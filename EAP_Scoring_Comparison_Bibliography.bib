@manual{colorBlindness,
    title = {colorBlindness: Safe Color Set for Color Blindness},
    author = {Jianhong Ou},
    year = {2021},
    note = {R package version 0.1.9},
    url = {https://CRAN.R-project.org/package=colorBlindness},
  }

@manual{ThetaSEeap,
  author = "Seung Choi",
  title = "ThetaSEeap.R",
  howpublished = "Version 1.",
  year = "2010.",

}

@manual{RSSS,
  author = "Seung Choi",
  title = "RSSS.R",
  howpublished = "Version 1.",
  year = "2010.",

}



@book{APADictionary,
address = {Washington, DC},
booktitle = {APA dictionary of psychology},
edition = {1st ed.},
isbn = {1591473802},
keywords = {Psychology -- Dictionaries},
language = {eng},
lccn = {2006010293},
publisher = {American Psychological Association},
title = {APA dictionary of psychology },
year = {2007},
}



@article{Chang2005IRT,
abstract = {This article provides an overview of item response theory (IRT) models and how they can be appropriately applied to patient-reported outcomes (PROs) measurement. Specifically, the following topics are discussed: (a) basics of IRT, (b) types of IRT models, (c) how IRT models have been applied to date, and (d) new directions in applying IRT to PRO measurements.},
author = {Chang, Chih-Hung and Reeve, Bryce B},
address = {Los Angeles, CA},
issn = {0163-2787},
journal = {Evaluation & the health professions},
keywords = {Health Services Research - methods ; Outcome Assessment (Health Care) - methods ; Models, Statistical ; Humans ; Mathematical Computing ; Health technology assessment ; Health administration},
language = {eng},
number = {3},
pages = {264-282},
publisher = {SAGE Publications},
title = {Item Response Theory and its Applications to Patient-Reported Outcomes Measurement},
volume = {28},
year = {2005},
}

@article{Choi2014DepLink,
abstract = {Interest in measuring patient-reported outcomes has increased dramatically in recent decades. This has simultaneously produced numerous assessment options and confusion. In the case of depressive symptoms, there are many commonly used options for measuring the same or a very similar concept. Public and professional reporting of scores can be confused by multiple scale ranges, normative levels, and clinical thresholds. A common reporting metric would have great value and can be achieved when similar instruments are administered to a single sample and then linked to each other to produce cross-walk score tables (e.g., Dorans, 2007; Kolen & Brennan, 2004). Using multiple procedures based on item response theory and equipercentile methods, we produced cross-walk tables linking 3 popular "legacy" depression instruments-the Center for Epidemiologic Studies Depression Scale (Radloff, 1977; N = 747), the Beck Depression Inventory-II (Beck, Steer, & Brown, 1996; N = 748), and the 9-item Patient Health Questionnaire (Kroenke, Spitzer, & Williams, 2001; N = 1,120)-to the depression metric of the National Institutes of Health (NIH) Patient-Reported Outcomes Measurement Information System (PROMIS; Cella et al., 2010). The PROMIS Depression metric is centered on the U.S. general population, matching the marginal distributions of gender, age, race, and education in the 2000 U.S. census (Liu et al., 2010). The linking relationships were evaluated by resampling small subsets and estimating confidence intervals for the differences between the observed and linked PROMIS scores; in addition, PROMIS cutoff scores for depression severity were estimated to correspond with those commonly used with the legacy measures. Our results allow clinicians and researchers to retrofit existing data of 3 popular depression measures to the PROMIS Depression metric and vice versa.},
author = {Choi, Seung and Schalet, Benjamin and Cook, Karon F and Cella, David},
address = {Washington, DC},
copyright = {2014 American Psychological Association},
issn = {1040-3590},
journal = {Psychological assessment},
keywords = {Psychology. Psychoanalysis. Psychiatry ; Techniques and methods ; Adult and adolescent clinical studies ; Psychopathology. Psychiatry ; Psychometrics. Diagnostic aid systems ; Mood disorders ; Biological and medical sciences ; Depression ; Medical sciences ; Psychiatric Status Rating Scales - statistics & numerical data ; Reproducibility of Results ; Humans ; Middle Aged ; Depressive Disorder - diagnosis ; Female ; Male ; Psychometrics ; Surveys and Questionnaires ; Usage ; Care and treatment ; Item response theory ; Depression, Mental ; Analysis ; Diagnosis ; Epidemiology ; Mental depression ; Gender ; Information systems ; Index Medicus ; CES-D ; BDI-II ; PHQ-9 ; PROMIS ; linking},
language = {eng},
number = {2},
pages = {513-527},
publisher = {American Psychological Association},
title = {Establishing a Common Metric for Depressive Symptoms: Linking the BDI-II, CES-D, and PHQ-9 to PROMIS Depression},
volume = {26},
year = {2014},
}



@article{Rothrock2020TscoreMaps,
abstract = {Accurate score interpretation is required for the appropriate use of patient-reported outcome measures in clinical practice.
To create and evaluate figures (T-score Maps) to facilitate the interpretation of scores on Patient-Reported Outcome Measurement Information System (PROMIS) measures.
For 21 PROMIS® short forms, item-level information was used to predict the most probable responses to items for the range of possible scores on each short form. Predicted responses were then "mapped" graphically along the range of possible scores. In a previously conducted longitudinal study, 1594 adult participants with chronic conditions (e.g., multiple sclerosis) responded to four items each of a subset of these PROMIS short forms. Participants' responses to these items were compared to those predicted by the T-score Maps. Difference scores were calculated between observed and predicted scores, and Spearman correlations were calculated.
We constructed T-score Maps for 21 PROMIS short forms for adults and pediatric self- and parent-proxy report. For the clinical population, participants' actual responses were strongly correlated with their predicted responses (r = 0.762 to 0.950). The majority of predicted responses exactly matched observed responses (range 69.5% to 85.3%).
Results support the validity of the predicted responses used to construct T-score Maps. T-score Maps are ready to be tested as interpretation aids in a variety of applications.},
author = {Rothrock, Nan E and Amtmann, Dagmar and Cook, Karon F},
address = {Germany},
copyright = {Journal of Patient-Reported Outcomes is a copyright of Springer, (2020). All Rights Reserved. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
issn = {2509-8020},
journal = {Journal of patient-reported outcomes},
keywords = {PROMIS ; Item response theory ; Patient-reported outcomes},
language = {eng},
number = {1},
pages = {16-16},
publisher = {Springer Nature B.V},
title = {Development and validation of an interpretive guide for PROMIS scores},
volume = {4},
year = {2020},
}



@article{Hahn2016TPsw,
abstract = {Abstract Objectives To conduct a longitudinal evaluation of Patient-Reported Outcomes Measurement Information System (PROMIS) social function measures (satisfaction with participation in social roles and satisfaction with participation in discretionary social activities) in English-speaking people with chronic health conditions. Study Design and Setting Adults receiving treatment for chronic heart failure (CHF), chronic obstructive pulmonary disease (COPD), chronic back pain, or depression completed PROMIS computer-based measures of social health at two time points approximately 3 months apart and global ratings of change. Linear mixed effects models and standardized response means were estimated for the two social function measures. Results A total of 599 people participated: 79 with stable COPD, 46 COPD exacerbation, 60 with CHF, 196 with depression, and 218 with back pain. Four groups experienced improvement over time, one (COPD stable) changed very little. Those who reported better global ratings of change in overall health experienced larger changes in social function than those who reported the same or worse global health. Conclusion This study provided support for responsiveness to change for two PROMIS social function measures. These results provide further evidence of the PROMIS goal to enable comparable measurement of universally relevant symptoms and experiences that apply to people with a variety of diseases.},
author = {Hahn, Elizabeth A and Beaumont, Jennifer L and Pilkonis, Paul A and Garcia, Sofia F and Magasi, Susan and DeWalt, Darren A and Cella, David},
copyright = {Elsevier Inc.},
issn = {0895-4356},
journal = {Journal of clinical epidemiology},
keywords = {Internal Medicine ; patient-reported outcomes ; social health ; PROMIS ; social function ; responsiveness},
language = {eng},
pages = {135-141},
title = {The PROMIS satisfaction with social participation measures demonstrate responsiveness in diverse clinical populations},
volume = {73},
year = {2016},
}

@article{CellaD2016PFIB,
abstract = {To evaluate the comparability and responsiveness of Patient-Reported Outcomes Measurement Information System (PROMIS) fatigue item bank across six chronic conditions.
Individuals (n = 1,430) with chronic obstructive pulmonary disease (n = 125), chronic heart failure (n = 60), chronic back pain (n = 218), major depressive disorder (n = 196), rheumatoid arthritis (n = 521), and cancer (n = 310) completed assessments from the PROMIS fatigue item bank at baseline and a clinically relevant follow-up. The cancer and arthritis samples were followed in observational studies; the other four groups were enrolled immediately before a planned clinical intervention. All participants completed global ratings of change at follow-up. Linear mixed-effects models and standardized response means were estimated to examine clinical validity and responsiveness to change.
All patient groups reported more fatigue than the general population (range = 0.2–1.29 standard deviation worse). The four clinical groups with pretreatment baseline data experienced significant improvement in fatigue at follow-up (effect size range = 0.25–0.91). Individuals reporting better overall health usually experienced larger fatigue changes than those reporting worse overall health.
The results support the PROMIS fatigue measures's responsiveness to change in six different chronic conditions. In addition, these results support the ability of the PROMIS fatigue measures to compare differences in fatigue across a range of chronic conditions, thereby enabling comparative effectiveness research.},
author = {Cella, David and Lai, Jin-Shei and Jensen, Sally E and Christodoulou, Christopher and Junghaenel, Doerte U and Reeve, Bryce B and Stone, Arthur A},
address = {United States},
copyright = {2016 Elsevier Inc.},
issn = {0895-4356},
journal = {Journal of clinical epidemiology},
keywords = {Responsiveness ; Fatigue ; Chronic conditions ; Item bank ; Patient-reported outcomes ; PROMIS ; Reproducibility of Results ; Comorbidity ; Humans ; Middle Aged ; Self Report ; Chronic Disease - epidemiology ; Male ; Psychometrics ; Fatigue - diagnosis ; Young Adult ; Fatigue - epidemiology ; Adolescent ; Adult ; Female ; Aged ; Surveys and Questionnaires - standards ; Medical policy ; Medical colleges ; Banks (Finance) ; Rheumatoid factor ; Lung diseases, Obstructive ; Depression, Mental ; Arthritis ; Backache ; Index Medicus},
language = {eng},
pages = {128-134},
publisher = {Elsevier Inc},
title = {PROMIS Fatigue Item Bank had Clinical Validity across Diverse Chronic Conditions},
volume = {73},
year = {2016},
}


@article{AskewR2016CVoP,
author = {Askew, Robert L and Cook, Karon F and Revicki, Dennis A and Cella, David and Amtmann, Dagmar},
issn = {0895-4356},
journal = {Journal of clinical epidemiology},
keywords = {pain interference ; chronic pain ; cancer ; back pain ; PROMIS ; pain behavior},
language = {eng},
pages = {103-111},
title = {Clinical Validity of PROMIS® Pain Interference and Pain Behavior in Diverse Clinical Populations},
volume = {73},
year = {2016},
}


@article{SchaletB2016VoPp,
abstract = {Abstract Objectives To evaluate the validity of the Patient-Reported Outcomes Measurement Information System (PROMIS) Physical Function measures using longitudinal data collected in six chronic health conditions. Study Design and Setting Individuals with rheumatoid arthritis (RA), major depressive disorder (MDD), back pain, chronic obstructive pulmonary disease (COPD), chronic heart failure (CHF), and cancer completed the PROMIS Physical Function computerized adaptive test or fixed-length short form at baseline and at the end of clinically relevant follow-up intervals. Anchor items were also administered to assess change in physical function and general health. Linear mixed-effects models and standardized response means were estimated at baseline and follow-up. Results A total of 1,415 individuals participated (COPD n  = 121; CHF n  = 57; back pain n  = 218; MDD n  = 196; RA n  = 521; cancer n  = 302). The PROMIS Physical Function scores improved significantly for treatment of CHF and back pain patients but not for patients with MDD or COPD. Most of the patient subsamples that reported improvement or worsening on the anchors showed a corresponding positive or negative change in PROMIS Physical Function. Conclusion This study provides evidence that the PROMIS Physical Function measures are sensitive to change in intervention studies where physical function is expected to change and able to distinguish among different clinical samples. The results inform the estimation of meaningful change, enabling comparative effectiveness research.},
author = {Schalet, Benjamin D and Hays, Ron D and Jensen, Sally E and Beaumont, Jennifer L and Fries, James F and Cella, David},
copyright = {Elsevier Inc.},
issn = {0895-4356},
journal = {Journal of clinical epidemiology},
keywords = {Internal Medicine ; Patient-reported Outcome ; Chronic Conditions ; Physical Function ; Item Bank ; PROMIS},
language = {eng},
pages = {112-118},
title = {Validity of PROMIS physical function measures in diverse clinical samples},
volume = {73},
year = {2016},
}

@article{CookK2016Pmop,
abstract = {Abstract Objective To present an overview of a series of studies in which the clinical validity of the National Institutes of Health's Patient Reported Outcome Measurement Information System (NIH; PROMIS) measures was evaluated, by domain, across six clinical populations. Study Design and Setting Approximately 1,500 individuals at baseline and 1,300 at follow-up completed PROMIS measures. The analyses reported in this issue were conducted post hoc, pooling data across six previous studies, and accommodating the different designs of the six, within-condition, parent studies. Changes in T-scores, standardized response means, and effect sizes were calculated in each study. When a parent study design allowed, known groups validity was calculated using a linear mixed model. Results The results provide substantial support for the clinical validity of nine PROMIS measures in a range of chronic conditions. Conclusion The cross-condition focus of the analyses provided a unique and multifaceted perspective on how PROMIS measures function in “real-world” clinical settings and provides external anchors that can support comparative effectiveness research. The current body of clinical validity evidence for the nine PROMIS measures indicates the success of NIH PROMIS in developing measures that are effective across a range of chronic conditions.},
author = {Cook, Karon F and Jensen, Sally E and Schalet, Benjamin D and Beaumont, Jennifer L and Amtmann, Dagmar and Czajkowski, Susan and Dewalt, Darren A and Fries, James F and Pilkonis, Paul A and Reeve, Bryce B and Stone, Arthur A and Weinfurt, Kevin P and Cella, David},
copyright = {Elsevier Inc.},
issn = {0895-4356},
journal = {Journal of clinical epidemiology},
keywords = {Internal Medicine ; Responsiveness ; Validity ; Psychometrics ; Patient-reported outcomes ; Outcomes research},
language = {eng},
pages = {89-102},
title = {PROMIS® measures of pain, fatigue, negative affect, physical function, and social function demonstrate clinical validity across a range of chronic conditions},
volume = {73},
year = {2016},
}

@article{SchaletB2016CvoP,
abstract = {Abstract Objectives The purpose of this study was to evaluate the responsiveness to change of the PROMIS negative affect measures (depression, anxiety, and anger) using longitudinal data collected in six chronic health conditions. Study Design and Setting Individuals with major depressive disorder (MDD), back pain, chronic obstructive pulmonary disease (COPD), chronic heart failure (CHF), and cancer completed PROMIS negative affect instruments as computerized adaptive test or as fixed-length short form at baseline and a clinically relevant follow-up interval. Participants also completed global ratings of health. Linear mixed effects models and standardized response means (SRM) were estimated at baseline and follow-up. Results A total of 903 individuals participated (back pain, n  = 218; cancer, n  = 304; CHF, n  = 60; COPD, n  = 125; MDD, n  = 196). All three negative affect instruments improved significantly for treatments of depression and pain. Depression improved for CHF patients (anxiety and anger not administered), whereas anxiety improved significantly in COPD groups (stable and exacerbation). Response to treatment was not assessed in cancer. Subgroups of patients reporting better or worse health showed a corresponding positive or negative average SRM for negative affect across samples. Conclusion This study provides evidence that the PROMIS negative affect scores are sensitive to change in intervention studies in which negative affect is expected to change. These results inform the estimation of meaningful change and enable comparative effectiveness research.},
author = {Schalet, Benjamin D and Pilkonis, Paul A and Yu, Lan and Dodds, Nathan and Johnston, Kelly L and Yount, Susan and Riley, William and Cella, David},
address = {United States},
copyright = {Elsevier Inc.},
issn = {0895-4356},
journal = {Journal of clinical epidemiology},
keywords = {Internal Medicine ; Anger ; Depression ; Chronic conditions ; Anxiety ; Item bank ; PROMIS ; Reproducibility of Results ; Follow-Up Studies ; Comorbidity ; Humans ; Middle Aged ; Self Report ; Depressive Disorder - diagnosis ; Anxiety Disorders - diagnosis ; Anxiety Disorders - epidemiology ; Chronic Disease - epidemiology ; Male ; Psychometrics ; Anxiety Disorders - psychology ; Young Adult ; Adolescent ; Adult ; Female ; Aged ; Depressive Disorder - epidemiology ; Depressive Disorder - psychology ; Chronic Disease - psychology ; Longitudinal Studies ; Surveys and Questionnaires - standards ; Medical colleges ; Depression, Mental ; Medicine, Experimental ; Medical research ; Lung diseases, Obstructive ; Backache ; Index Medicus ; Chronic Conditions ; Item Bank},
language = {eng},
pages = {119-127},
publisher = {Elsevier Inc},
title = {Clinical validity of PROMIS Depression, Anxiety, and Anger across diverse clinical samples},
volume = {73},
year = {2016},
}

@article{Hanmer2020Checklist,
abstract = {ASCQ-Me®, Neuro-QoL™, NIH Toolbox®, and PROMIS®, which are health-related quality of life measures collectively known as HealthMeasures, have experienced rapid uptake in the scientific community with over 1700 peer-reviewed publications through 2018. Because of their proliferation across multiple research disciplines, there has been significant heterogeneity in the description and reporting of these measures. Here, we provide a publication checklist to promote standardization and comparability across different reports. This checklist can be used across all HealthMeasures systems. Checklist Development: Authors drafted a draft checklist, circulated among the HealthMeasures Steering Committee and PROMIS Health Organization until the members reached consensus. Checklist: The final checklist has 21 entries in 4 categories: measure details, administration, scoring, and reporting. Most entries (11) specify necessary measure-specific details including version number and administration language(s). Administration (4 entries) reminds authors to include details such as use of proxy respondents and the assessment platform. Scoring (3 entries) is necessary to ensure replication and cross-study comparisons. Reporting (3 entries) reminds authors to always report scores on the T-score metric.
Consistent documentation is necessary to ensure transparent and reproducible methods and support the accumulation of evidence across studies. This checklist promotes standardization and completeness in documentation for ASCQ-Me, Neuro-QoL, PROMIS, and NIH Toolbox measures.},
author = {Hanmer, Janel and Jensen, Roxanne E and Rothrock, Nan},
address = {Germany},
copyright = {Journal of Patient-Reported Outcomes is a copyright of Springer, (2020). All Rights Reserved. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
issn = {2509-8020},
journal = {Journal of patient-reported outcomes},
keywords = {NIH Toolbox ; ASCQ-Me ; Patient-reported outcomes ; PROMIS ; Neuro-QoL},
language = {eng},
number = {1},
organization = {HealthMeasures Team},
pages = {21-21},
publisher = {Springer Nature B.V},
title = {A reporting checklist for HealthMeasures' patient-reported outcomes: ASCQ-Me, Neuro-QoL, NIH Toolbox, and PROMIS},
volume = {4},
year = {2020},
}

@Manual{RMarkdown,
  title = {rmarkdown: Dynamic Documents for R},
  author = {JJ Allaire and Yihui Xie and Jonathan McPherson and
    Javier Luraschi and Kevin Ushey and Aron Atkins and Hadley
    Wickham and Joe Cheng and Winston Chang and Richard Iannone},
  year = {2021},
  note = {R package version 2.8},
  url = {https://github.com/rstudio/rmarkdown},
}

@article{Stover2019PRO,
abstract = {This paper is part of a series comparing different psychometric approaches to evaluate patient-reported outcome (PRO) measures using the same items and dataset. We provide an overview and example application to demonstrate 1) using item response theory (IRT) to identify poor and well performing items; 2) testing if items perform differently based on demographic characteristics (differential item functioning, DIF); and 3) balancing IRT and content validity considerations to select items for short forms.Model fit, local dependence, and DIF were examined for 51 items initially considered for the Patient-Reported Outcomes Measurement Information System® (PROMIS®) Depression item bank. Samejima’s graded response model was used to examine how well each item measured severity levels of depression and how well it distinguished between individuals with high and low levels of depression. Two short forms were constructed based on psychometric properties and consensus discussions with instrument developers, including psychometricians and content experts. Calibrations presented here are for didactic purposes and are not intended to replace official PROMIS parameters or to be used for research.Of the 51 depression items, 14 exhibited local dependence, 3 exhibited DIF for gender, and 9 exhibited misfit, and these items were removed from consideration for short forms. Short form 1 prioritized content, and thus items were chosen to meet DSM-V criteria rather than being discarded for lower discrimination parameters. Short form 2 prioritized well performing items, and thus fewer DSM-V criteria were satisfied. Short forms 1–2 performed similarly for model fit statistics, but short form 2 provided greater item precision.IRT is a family of flexible models providing item- and scale-level information, making it a powerful tool for scale construction and refinement. Strengths of IRT models include placing respondents and items on the same metric, testing DIF across demographic or clinical subgroups, and facilitating creation of targeted short forms. Limitations include large sample sizes to obtain stable item parameters, and necessary familiarity with measurement methods to interpret results. Combining psychometric data with stakeholder input (including people with lived experiences of the health condition and clinicians) is highly recommended for scale development and evaluation.},
author = {Stover, Angela M and McLeod, Lori D and Langer, Michelle M and Chen, Wen-Hung and Reeve, Bryce B},
address = {Cham},
copyright = {The Author(s) 2019},
issn = {2509-8020},
journal = {Journal of patient-reported outcomes},
keywords = {Measurement ; Medicine & Public Health ; Item response theory ; PROMIS ; Quality of Life Research ; Scale construction ; Scale evaluation ; Quantitative psychology},
language = {eng},
number = {1},
pages = {1-16},
publisher = {Springer International Publishing},
title = {State of the psychometric methods: patient-reported outcome measure development and refinement using item response theory},
volume = {3},
year = {2019},
}




@article{Lord1984RSSS,
abstract = {Two methods of 'equating' tests are compared, one using true scores, the other using equipercentile equat ing of observed scores. The theory of equating is dis cussed. For the data studied, the two methods yield almost indistinguishable results.},
author = {Lord, Frederic M and Wingersky, Marilyn S},
address = {Thousand Oaks, CA},
copyright = {1986 INIST-CNRS},
issn = {0146-6216},
journal = {Applied psychological measurement},
keywords = {Fundamental and applied biological sciences. Psychology ; Psychometrics. Statistics. Methodology ; Biological and medical sciences ; Psychology. Psychoanalysis. Psychiatry ; Statistics. Mathematics ; Psychology. Psychophysiology},
language = {eng},
number = {4},
pages = {453-461},
publisher = {Sage Publications},
title = {Comparison of IRT True-Score and Equipercentile Observed-Score "Equatings"},
volume = {8},
year = {1984},
}

@article{Cai2015RSSS,
abstract = {Lord and Wingersky’s (Appl Psychol Meas 8:453–461, 1984) recursive algorithm for creating summed score based likelihoods and posteriors has a proven track record in unidimensional item response theory (IRT) applications. Extending the recursive algorithm to handle multidimensionality is relatively simple, especially with fixed quadrature because the recursions can be defined on a grid formed by direct products of quadrature points. However, the increase in computational burden remains exponential in the number of dimensions, making the implementation of the recursive algorithm cumbersome for truly high-dimensional models. In this paper, a dimension reduction method that is specific to the Lord–Wingersky recursions is developed. This method can take advantage of the restrictions implied by hierarchical item factor models, e.g., the bifactor model, the testlet model, or the two-tier model, such that a version of the Lord–Wingersky recursive algorithm can operate on a dramatically reduced set of quadrature points. For instance, in a bifactor model, the dimension of integration is always equal to 2, regardless of the number of factors. The new algorithm not only provides an effective mechanism to produce summed score to IRT scaled score translation tables properly adjusted for residual dependence, but leads to new applications in test scoring, linking, and model fit checking as well. Simulated and empirical examples are used to illustrate the new applications.},
author = {Cai, Li},
address = {New York},
copyright = {The Psychometric Society 2014},
issn = {0033-3123},
journal = {Psychometrika},
keywords = {test equating ; Psychology ; linking ; Assessment, Testing and Evaluation ; Psychometrics ; Statistical Theory and Methods ; bifactor model ; summed score ; scale alignment ; goodness-of-fit testing ; multidimensional item response theory ; testlet ; Statistics for Social Science, Behavorial Science, Education, Public Policy, and Law ; Educational Measurement ; Likelihood Functions ; Factor Analysis, Statistical ; Algorithms ; Models, Statistical ; Index Medicus},
language = {eng},
number = {2},
pages = {535-559},
publisher = {Springer US},
title = {Lord–Wingersky Algorithm Version 2.0 for Hierarchical Item Factor Models with Applications in Test Scoring, Scale Alignment, and Model Fit Testing},
volume = {80},
year = {2015},
}



@article{Gershon2010AC,
author = {Gershon, Richard and Rothrock, Nan and Hanrahan, Rachel and Bass, Michael and Cella, David},
copyright = {2010},
journal = {Journal of Applied Measurement},
language = {eng},
number = {3},
pages = {304-314},
title = {The Use of PROMIS and Assessment Center to Deliver Patient-Reported Outcome Measures in Clinical Research},
volume = {11},
year = {2010},
}



@article{Rose2014PF,
abstract = {Abstract Objective To document the development and psychometric evaluation of the Patient-Reported Outcomes Measurement Information System (PROMIS) Physical Function (PF) item bank and static instruments. Study Design and Setting The items were evaluated using qualitative and quantitative methods. A total of 16,065 adults answered item subsets ( n > 2,200/item) on the Internet, with oversampling of the chronically ill. Classical test and item response theory methods were used to evaluate 149 PROMIS PF items plus 10 Short Form-36 and 20 Health Assessment Questionnaire-Disability Index items. A graded response model was used to estimate item parameters, which were normed to a mean of 50 (standard deviation [SD] = 10) in a US general population sample. Results The final bank consists of 124 PROMIS items covering upper, central, and lower extremity functions and instrumental activities of daily living. In simulations, a 10-item computerized adaptive test (CAT) eliminated floor and decreased ceiling effects, achieving higher measurement precision than any comparable length static tool across four SDs of the measurement range. Improved psychometric properties were transferred to the CAT's superior ability to identify differences between age and disease groups. Conclusion The item bank provides a common metric and can improve the measurement of PF by facilitating the standardization of patient-reported outcome measures and implementation of CATs for more efficient PF assessments over a larger range.},
author = {Rose, Matthias and Bjorner, Jakob B and Gandek, Barbara and Bruce, Bonnie and Fries, James F and Ware, John E},
address = {New York, NY},
copyright = {2014},
issn = {0895-4356},
journal = {Journal of clinical epidemiology},
keywords = {Internal Medicine ; Computerized adaptive test ; Health status ; Questionnaire ; Patient-reported outcomes ; Item response theory ; Physical function ; Public health. Hygiene-occupational medicine ; Public health. Hygiene ; General aspects ; Analysis. Health state ; Biological and medical sciences ; Medical sciences ; Epidemiology ; Disability Evaluation ; Reproducibility of Results ; Humans ; Middle Aged ; Male ; Psychometrics ; Calibration ; Young Adult ; Adolescent ; Aged, 80 and over ; Adult ; Female ; Surveys and Questionnaires ; Aged ; Qualitative Research ; Measurement ; Bank management ; Banks (Finance) ; Public health ; Index Medicus ; health status ; questionnaire ; physical function ; Item Response Theory ; Computer Adaptive Test},
language = {eng},
number = {5},
pages = {516-526},
publisher = {Elsevier Inc},
title = {The PROMIS Physical Function item bank was calibrated to a standardized metric and shown to improve measurement efficiency},
volume = {67},
year = {2014},
}

@article{Reeve2007PROMISPsychm,
abstract = {Background: The construction and evaluation of item banks to measure unidimensional constructs of health-related quality of life (HRQOL) is a fundamental objective of the Patient-Reported Outcomes Measurement Information System (PROMIS) project. Objectives: Item banks will be used as the foundation for developing short-form instruments and enabling computerized adaptive testing. The PROMIS Steering Committee selected 5 HRQOL domains for initial focus: physical functioning, fatigue, pain, emotional distress, and social role participation. This report provides an overview of the methods used in the PROMIS item analyses and proposed calibration of item banks. Analyses: Analyses include evaluation of data quality (eg, logic and range checking, spread of response distribution within an item), descriptive statistics (eg, frequencies, means), item response theory model assumptions (unidimensionality, local independence, monotonicity), model fit, differential item functioning, and item calibration for banking. Recommendations: Summarized are key analytic issues; recommendations are provided for future evaluations of item banks in HRQOL assessment.},
author = {Bryce Reeve and Ron D. Hays and Jakob B. Bjorner and Karon F. Cook and Paul K. Crane and Jeanne A. Teresi and David Thissen and Dennis A. Revicki and David J. Weiss and Ronald K. Hambleton and Honghu Liu and Richard Gershon and Steven P. Reise and Jin-Shei Lai and David Cella},
address = {United States},
copyright = {Copyright 2007 Lippincott Williams & Wilkins},
issn = {0025-7079},
journal = {Medical care},
keywords = {Factor analysis ; Demography ; Item response theory ; Psychometrics ; Standard deviation ; Calibration ; Modeling ; Test bias ; Parametric models ; Quality of life ; Outcome Assessment (Health Care) - methods ; United States ; Humans ; Middle Aged ; Information Systems ; Male ; Self Disclosure ; Databases as Topic ; Adolescent ; Quality of Life ; Adult ; Female ; Aged ; Health Status ; Surveys and Questionnaires - standards ; Evaluation Studies as Topic ; Health care ; Patients ; Clinical outcomes ; Health informatics ; Information systems ; Index Medicus},
language = {eng},
number = {5},
organization = {PROMIS Cooperative Group},
pages = {S22-S31},
publisher = {Lippincott Williams & Wilkins},
title = {Psychometric Evaluation and Calibration of Health-Related Quality of Life Item Banks: Plans for the Patient-Reported Outcomes Measurement Information System (PROMIS)},
volume = {45},
year = {2007},
}

@article{Nguyen2014IRTPCO,
abstract = {The growing emphasis on patient-centered care has accelerated the demand for high-quality data from patient-reported outcome (PRO) measures. Traditionally, the development and validation of these measures has been guided by classical test theory. However, item response theory (IRT), an alternate measurement framework, offers promise for addressing practical measurement problems found in health-related research that have been difficult to solve through classical methods. This paper introduces foundational concepts in IRT, as well as commonly used models and their assumptions. Existing data on a combined sample (n = 636) of Korean American and Vietnamese American adults who responded to the High Blood Pressure Health Literacy Scale and the Patient Health Questionnaire-9 are used to exemplify typical applications of IRT. These examples illustrate how IRT can be used to improve the development, refinement, and evaluation of PRO measures. Greater use of methods based on this framework can increase the accuracy and efficiency with which PROs are measured.},
author = {Nguyen, Tam H and Han, Hae-Ra and Kim, Miyong T and Chan, Kitty S},
address = {Cham},
copyright = {Springer International Publishing Switzerland 2014},
issn = {1178-1653},
journal = {The patient : patient-centered outcomes research},
keywords = {Quality of Life Research ; Health Economics ; Health Administration ; Public Health ; Pharmacoeconomics and Health Outcomes ; Medicine & Public Health ; Health Services Research - methods ; Humans ; Hypertension - ethnology ; Patient-Centered Care ; Health Literacy ; Asian Americans - psychology ; Mental Health ; Patient Outcome Assessment ; Health Status ; Outcome and process assessment (Health Care) ; Usage ; Item response theory ; Methods ; Software ; Mathematical models ; Product testing ; Diabetes ; Theory ; Quality of life ; Index Medicus},
language = {eng},
number = {1},
pages = {23-35},
publisher = {Springer International Publishing},
title = {An Introduction to Item Response Theory for Patient-Reported Outcome Measurement},
volume = {7},
year = {2014},
}

@article{Cella2010PROMIS,
author = {Cella, David and Riley, William and Stone, Arthur and Rothrock, Nan and Reeve, Bryce and Yount, Susan and Amtmann, Dagmar and Bode, Rita and Buysse, Daniel and Choi, Seung and Cook, Karon and DeVellis, Robert and DeWalt, Darren and Fries, James F and Gershon, Richard and Hahn, Elizabeth A and Lai, Jin-Shei and Pilkonis, Paul and Revicki, Dennis and Rose, Matthias and Weinfurt, Kevin and Hays, Ron},
issn = {0895-4356},
journal = {Journal of clinical epidemiology},
keywords = {Chronic disease ; Outcome Measures ; Quality of life},
language = {eng},
number = {11},
pages = {1179-1194},
title = {Initial Adult Health Item Banks and First Wave Testing of the Patient-Reported Outcomes Measurement Information System (PROMIS™) Network: 2005–2008},
volume = {63},
year = {2010},
}

@book{Samejima1969,
author = {Samejima, Fumiko},
address = {New York, N.Y},
booktitle = {Estimation of latent ability using a response pattern of graded scores},
keywords = {Estimation theory},
language = {eng},
publisher = {Psychometric Society},
series = {Psychometrika. Monograph supplement ; monograph no. 17},
title = {Estimation of latent ability using a response pattern of graded scores },
year = {1969},
}

@article{Bock1982EAP,
abstract = {Expected a posteriori (EAP) estimation of ability, based on numerical evaluation of the mean and variance of the posterior distribution, is shown to have unusually good properties for computerized adaptive testing. The calculations are not complex, precede noniteratively by simple summation of log likelihoods as items are added, and require only values of the response function obtainable from precalculated tables at a limited number of quadrature points. Simulation studies are reported showing the near equivalence of the posterior standard deviation and the standard error of measurement. When the adaptive testings terminate at a fixed posterior standard deviation criterion of .90 or better, the regression of the EAP estimator on true ability is virtually linear with slope equal to the reliability, and the measurement error homogeneous, in the range ± 2.5 standard deviations.},
author = {Bock, R. Darrell and Mislevy, Robert J},
address = {Thousand Oaks, CA},
issn = {0146-6216},
journal = {Applied psychological measurement},
language = {eng},
number = {4},
pages = {431-444},
publisher = {Sage Publications},
title = {Adaptive EAP Estimation of Ability in a Microcomputer Environment},
volume = {6},
year = {1982},
}

@article{Bock1981MMLE,
author = {Bock, R. Darrell and Aitkin, Murray},
address = {Colorado Springs, Colo},
issn = {0033-3123},
journal = {Psychometrika},
language = {eng},
number = {4},
pages = {443-459},
publisher = {Psychometric Society, etc},
title = {Marginal maximum likelihood estimation of item parameters: Application of an EM algorithm},
volume = {46},
year = {1981},
}

@inbook{ReeveFayers2005IRT,
title = "Applying item response theory modelling for evaluating questionnaire item and scale properties",
author = "Bryce Reeve and Peter Fayers",
year = "2005",
language = "English",
isbn = "0-1985-2769-1",
pages = "55--73",
booktitle = "In: Assessing Quality of Life in Clinical Trials: Methods and Practice 2nd edn (ed Fayers,P. M.;Hays,R. D.), Oxford University Press, Oxford",
}