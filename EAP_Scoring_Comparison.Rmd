---
title: "Expected A Posteriori Scoring in PROMIS^Â®^"
author: "Robert Chapman"
date: "7/16/2021"
output: 
  bookdown::word_document2:
    reference_docx: ["apa_template.docx"]
bibliography: ["EAP_in_PROMIS_Bibliography.bib"]
csl: ["apa.csl"]
link-citations: true
---


<!--
Northwestern University

Author Note
Robert Chapman, Department of Medical Social Sciences, Feinberg School of Medicine, Northwestern University. 

Correspondence concerning this article should be addressed to Robert Chapman, Department of Medical Social Sciences, Feinberg School of Medicine, Northwestern University, 625 North Michigan Avenue, Chicago, Illinois, 60601. 
Contact: Robert.Chapman@northwestern.edu -->

<!-- new page below for title/coverpage, title is automatically generated by R Markdown -->
\newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

# This R Markdown chunk sets up functions and objects containing IRT item parameters for later R Markdown script 

# Items: List object of PROMIS items, their text/stem & response options and item calibration statistics
  Items=list(
    "Physical Function"=list(
      PFA51=list(
        "Stem"="Are you able to sit on the edge of a bed?",
        "ResponseOptions"=c("Without any difficulty"=5, "With a little difficulty"=4, "With some difficulty"=3, "With much difficulty"=2, "Unable to do"=1),
        "Calibrations"=data.frame("a"=3.220, "cb1"=-3.607, "cb2"=-3.129, "cb3"=-2.562, "cb4"=-2.024),
        "NCAT"=5),
      PFB25=list(
        "Stem"="Are you able to push open a door after turning the knob?",
        "ResponseOptions"=c("Without any difficulty"=5, "With a little difficulty"=4, "With some difficulty"=3, "With much difficulty"=2, "Unable to do"=1),
        "Calibrations"=data.frame("a"=3.340, "cb1"=-3.407, "cb2"=-2.910, "cb3"=-2.324, "cb4"=-1.669),
        "NCAT"=5),
      PFC46=list(
        "Stem"="Are you able to transfer from a bed to a chair and back?",
        "ResponseOptions"=c("Without any difficulty"=5, "With a little difficulty"=4, "With some difficulty"=3, "With much difficulty"=2, "Unable to do"=1),
        "Calibrations"=data.frame("a"=3.615, "cb1"=-3.478, "cb2"=-2.934, "cb3"=-2.328, "cb4"=-1.563),
        "NCAT"=5),
      PFA56=list(
        "Stem"="Are you able to get in and out of a car?",
        "ResponseOptions"=c("Without any difficulty"=5, "With a little difficulty"=4, "With some difficulty"=3, "With much difficulty"=2, "Unable to do"=1),
        "Calibrations"=data.frame("a"=3.243, "cb1"=-3.673, "cb2"=-2.745, "cb3"=-1.999, "cb4"=-1.107),
        "NCAT"=5),
      PFA16=list(
        "Stem"="Are you able to dress yourself, including tying shoelace and button your clothes?",
        "ResponseOptions"=c("Without any difficulty"=5, "With a little difficulty"=4, "With some difficulty"=3, "With much difficulty"=2, "Unable to do"=1),
        "Calibrations"=data.frame("a"=3.306, "cb1"=-3.187, "cb2"=-2.559, "cb3"=-1.934, "cb4"=-1.246),
        "NCAT"=5),
      PFA11=list(
        "Stem"="Are you able to do chores such as vacuuming or yard work?",
        "ResponseOptions"=c("Without any difficulty"=5, "With a little difficulty"=4, "With some difficulty"=3, "With much difficulty"=2, "Unable to do"=1),
        "Calibrations"=data.frame("a"=4.716, "cb1"=-1.987, "cb2"=-1.534, "cb3"=-1.094, "cb4"=-0.423),
        "NCAT"=5)),
    "Fatigue"=list(
      FATEXP42=list(
        "Stem"="How much mental energy did you have on average?",
        "ResponseOptions"=c("Not at all"=5, "A little bit"=4, "Somewhat"=3, "Quite a bit"=2, "Very much"=1),
        "Calibrations"=data.frame("a"=1.44166, "cb1"=-1.25974, "cb2"=0.78268, "cb3"=1.95133, "cb4"=3.5124),
        "NCAT"=5)))

# Theta quadrature settings for PROMIS EAP scoring 
  # Range of theta, -4 to 4 by increments of 0.1
    minTheta=-4; maxTheta=4; inc=0.1
  # theta: theta quadrature creation using 'sequence' function, rounded to one decimal to ensure no trailing digits
    theta<-seq(minTheta,maxTheta,inc);
    theta=round(theta,1)
  # Number or length of the theta quadrature, useful in declaring size of matrices, etc.
    nq<-length(theta);
    
# Create prior based on normal density of the theta quadrature
  # using the 'dnorm' function. The prior is
  # centered at (i.e., has a mean of) 0 and
  # has a standard deviation of 0.1
    prior<-dnorm(theta);
  
  
# Prep.prob is a function to calculate item response probabilities 
  # across the theta quadrature using item calibration statistics
    prep.prob<-function(){
    
# pp: 3d array, intialized with zeros, to later store EAP probabilities with 
    # array dimensions of
      # 1) nq: length of theta quadrature 
      # 2) ni: number of items 
      # 3) maxCat: number of response options  
    pp<-array(0,c(nq,ni,maxCat));
    
# for each item, "i" (i in 1:ni)...
  for (i in 1:ni) {
        
    #ps: 2d matrix, initialized with zeros, to later store threshold probabilities
      # matrix dimensions of
          # 1) nq: length of theta quadrature
          # 2) NCAT[i]+1: number of response options for the select item plus one 
      ps<-matrix(0,nq,NCAT[i]+1);
        

    # Create probability boundaries of 1 (certainty) and 0 (impossibility)
      # This will be used for later subtraction of threshold probabilities to create
      # extreme response option probabilities
      ps[,1]<-1; ps[,NCAT[i]+1]<-0;
        
     # For all item calibration thresholds, "k", (k in 1:(NCAT[i]-1) in select item "i"...        
      for (k in 1:(NCAT[i]-1)) {
        # between probabilities of 1 and 0 (see above),
          # populate the "ps" matrix with probabilities
          # from each item calibration threshold, k, for select item, i
          # using the graded response model formula
        ps[,k+1]<-1/(1+exp(-1*DISC[i]*(theta-CB[i,k])));
      }
        
      # For all item response options, "k", (k in 1:(NCAT[i]) in select item "i"...
      for (k in 1:NCAT[i]) {
        # Fill the final "pp" matrix with response option probabilities, 
          # calculated by subtracting adjacent threshold probabilities
          # note that extreme response options probabilities 
          # are extreme threshold probabilities minus 1 or 0
        pp[,i,k]=ps[,k]-ps[,k+1];
      }
    }
    # the prep.prob function returns a finalized matrix of response option probabilities
    return(pp);
  }
    
    
# Graphing 

# LineTypes: vector of numbers that will be used to set graphing line types, e.g., dot, dash, dot-dash
  # Set the 'Prior' and 'Posterior' line types equal to solid line (1)
  # Naming these line types helps with consistency and coding legibility
  LineTypes=c(2:6,1,1,"Prior"=1,"Posterior"=1)
  
# LineWidth: vector of numbers that will be used to set graphing line width
  # Set the 'Prior' and 'Posterior' line types equal to 1 (normal) and 2 (extra wide)
  # Naming these line types helps with consistency and coding legibility
  LineWidth=c(rep(1,7), "Prior"=1, "Posterior"=2)
    
# ColorPalette
  # install.packages("colorBlindness") #only run once to install package
  library(colorBlindness)
  
# Colors: vector of colors selected from 'paletteMartin' colorBlindness palette  
  Colors=paletteMartin[c("PigmentIndigo", "Malibu", "RedBerry", "PersianGreen", "CottonCandy", "LaserLemon", "SherpaBlue", "Harlequin", "MangoTango", "ScienceBlue")]
  # Set the 8th, 9th and 10th names of Colors equal to 'Prior' 'Posterior' and 'ThetaWeightedPosterior'
    # naming these colors is useful later, to help with coding legibility and consistency
    names(Colors)[8]="Prior"
    names(Colors)[9]="Posterior"
    names(Colors)[10]="ThetaWeightedPosterior"
    
# Create a set axis labels using whole numbers (via modulo operator) in the theta quadrature
  Theta_axis_lab=theta[theta%%1==0]
    
# Plotting Function, used in EAP score calculation figure
   CurlyBraces <- function(x, y, range, pos = 1, direction = 1, col="black", size=1 ) {
    
    # Modified Curly Bracket Function
      # from stackoverflow: https://stackoverflow.com/questions/6178763/how-to-add-braces-to-a-graph
      # Function to create curly braces
      # x, y position where to put the braces
      # range is the width
      # position: 1 vertical, 2 horizontal
      # direction: 1 left/down, 2 right/up
      
        a=c(1,2,3,48,50)    # set flexion point for spline
        b=c(0,.2,.28,.7,.8)*size # set depth for spline flexion point
    
        curve = spline(a, b, n = 50, method = "natural")$y / 2 
    
        curve = c(curve,rev(curve))
    
        a_sequence = rep(x,100)
        b_sequence = seq(y-range/2,y+range/2,length=100)  
    
        # direction
        if(direction==1)
        a_sequence = a_sequence+curve
        if(direction==2)
        a_sequence = a_sequence-curve
    
        # position
        if(pos==1)
        lines(a_sequence,b_sequence, col=col) # vertical
        if(pos==2)
        lines(b_sequence,a_sequence, col=col) # horizontal
    
        }

```


<!-- 

After knitting:
-Tables title APA, return, italicize & unbold
-table borders for APA style
-Center cover page title
-centering tables & figures after finishing

--->

# Abstract {.unnumbered}

The Patient-Reported Outcome Measurement Information System (PROMIS) uses Item Response Theory (IRT) and Expected A Posteriori (EAP) scoring methods to precisely score measures. EAP scoring is a flexible and accurate form of calculating scale scores using IRT model parameters. This tutorial provides a description and demonstration of the EAP scoring methods as implemented in PROMIS. Extensions and practical considerations of EAP scoring methods are discussed. All statistical examples and demonstration graphics presented in this tutorial are made available through the R Markdown framework. Commented statistical code for calculating EAP scores is included in appendices. 

# Translational Abstract {.unnumbered}

The PROMIS (Patient-Reported Outcome Measurement Information System) measurement system was developed to precisely and reliably measure health-related quality of life using the patientâs voice. To achieve these aims, PROMIS utilized Item Response Theory (IRT) methods in its development, validation and implementation. PROMIS uses a specific method to calculate scores, called Expected A Posteriori (EAP) scoring. EAP scoring methods are flexible, produce accurate scores and can be efficiently calculated by statistical software. This tutorial seeks to make EAP scoring methods transparent and accessible to larger audience through description, graphical demonstration and examples. Further applications and practical considerations of EAP scoring are presented and discussed. All materials used in this tutorial are made available through the R Markdown reproducibility framework and are intended to reviewed and reused. Commented statistical code for the calculation of EAP scores is included.

# Introduction {.unnumbered}

The Patient-Reported Outcome Measurement Information System (PROMIS^Â®^), @Cella2010PROMIS, is a disease-agnostic measurement system of health-related quality of life which utilizes Item Response Theory (IRT). PROMIS was originally created to leverage the benefits of IRT and Computer Adaptive Testing (CAT) to minimize patient response burden while maximizing measurement reliability. PROMIS measures have been shown to be reliable, valid and accurate in a variety of conditions and contexts [@SchaletB2016CvoP; @CookK2016Pmop; @SchaletB2016VoPp; @AskewR2016CVoP; @CellaD2016PFIB; @Hahn2016TPsw]. Over the past fifteen years, there has been substantial development, adoption and implementation of PROMIS [@Reeve2007PROMISPsychm; @Stover2019PRO]. Such efforts have leveraged IRT to increase the accessibility of and aid their interpretation, including T-score maps [@Rothrock2020TscoreMaps] and "linking" between non-PROMIS and PROMIS measures [@Choi2014DepLink].

However, despite its broad user base among clinicians and researchers and its recognition among regulators, the IRT scoring methods used in PROMIS are not well understood by the average user.

This tutorial aims to make PROMIS IRT scoring methods accessible to all users by supplementing foundational psychometric literature with non-technical descriptions and illustrative graphics. To the same end, this tutorial was created in the reproducibility framework of R Markdown [@RMarkdown]. An R Markdown document (.rmd) contains both commented  statistical code and the explanatory text in this document. Both the text and statistical code for scoring is intended to be reviewed and implemented by the reader. Included in the appendices of this tutorial are a set of annotated statistical programming scripts for scoring PROMIS measures.

```{r TableOfAbbreviations}
# This R Markdown chunk creates a Kable table of abbreviations used in the tutorial
knitr::kable(data.frame(matrix(ncol=2,byrow=TRUE,dimnames = list(c(),c("Abbreviation","Term")),
 data=c(
    "CAT","Computer Adaptive Test",
    "EAP","Expected A Posteriori",
    "IRT","Item Response Theory",
    "PROMIS","Patient Reported Outcomes Measurement Information System",
    "SD", "Standard Deviation"))),
 caption="Table of Abbreviations")
```

# IRT Foundations {.unnumbered}

The IRT methods employed in PROMIS were developed 40-50 years ago [@Samejima1969; @Lord1984RSSS; @Bock1982EAP] and have been used extensively in the educational field. Over the past two decades, researchers have also shown how IRT can be applied to patient-centered outcomes generally [@Nguyen2014IRTPCO; @ReeveFayers2005IRT] and documented how IRT has been applied in PROMIS specifically [@Reeve2007PROMISPsychm; @Stover2019PRO]. This tutorial only briefly reviews foundations of IRT in PROMIS and instead provides focused demonstration of PROMIS scoring methods.

## Response Probabilities {.unnumbered}  
### Building Block of IRT Scoring {.unnumbered}  
IRT ranks individuals and their responses to survey items across a latent trait, such as fatigue. Just as two different people might have different levels of fatigue, two different responses to a survey item relate to two different levels of fatigue. However, unlike many physiological traits and states (e.g., presence or absence of a cancerous tumor), a latent trait canât be directly measured with objective indicators [@APADictionary]. Instead, IRT allows us to infer where an individual most likely ranks on a latent trait continuum. The inference of where an individual ranks on a latent trait is made by transforming an individuals response to an item (e.g., *I feel tired* - *Never*, *Sometimes*, and *Always*) to a set of probabilities across all levels of the latent trait. Each probability in the set represents the likelihood that an individual who endorses a specific response option has a particular level of latent trait. Expected A Posteriori scoring reduces these probability sets to a single point-estimate of the latent trait (i.e., a score) and provides an estimate of variability and reliability of the point estimate of the latent trait (i.e., standard deviation or standard error).

Two things are required to calculate these probabilities for a PROMIS measure: item calibration statistics, such as those shown in Table \@ref(tab:TableOfCalibrations), and the graded response model formula shown in Formula \@ref(eq:Probability). The formula allows a mathematical transformation of an individual's response to an item to a set of probabilities across the spectrum of the latent trait. The graded response model formula is the companion equation for interpreting PROMIS item calibration statistics and calculating probabilities. The graded response model was originally published by @Samejima1969, but is explained in more accessible terms by Reeve, Chang and Fayers [@ReeveFayers2005IRT; @Chang2005IRT].

In Formula \@ref(eq:Probability) we can see the calibration statistics, annotated as "discrimination" and "threshold". Each item has one discrimination calibration statistic and a number of threshold calibration statistics equal to the number of response options minus one. An example is PROMIS Fatigue item FATEXP42 (*In the past 7 days, how much mental energy did you have on average?*) which has five response options (*Not at all*, *A little bit*, *Somewhat*, *Quite a bit*, and *Very much*). It follows that FATEXP42 has one discrimination calibration statistic (abbreviated "a"), and four threshold calibration statistics (abbreviated and numbered from "cb1" to "cb4"). The item calibrations for FATEXP42 were originally published in Figure 3 of @Gershon2010AC and are provided here in Table \@ref(tab:TableOfCalibrations) for reference.

The remaining undefined variable in Formula \@ref(eq:Probability) is "theta", which refers to the latent trait being measured (e.g., fatigue or physical functioning). Theta is actualized as a single number for an individual level of latent trait, ranging from negative infinity to infinity. For the purposes of scoring and interpreting PROMIS measures, the range of theta is limited to Â±4, with a higher theta relating to more of what is being measured measured, e.g., higher PROMIS Fatigue theta values relate to more fatigue or higher PROMIS Physical Function theta values relate to better physical functioning.

\begin{equation}
Probability =
{ \frac{1} {1+e^{-1*discrimination(theta-threshold)}} } 
(\#eq:Probability)
\end{equation}


```{r TableOfCalibrations}
# This R Markdown chunk creates a Kable table of item calibration statistics from PROMIS Fatigue item FATEXP42
knitr::kable(round(Items$Fatigue$FATEXP42$Calibrations,2), caption="IRT Calibration Statistics for PROMIS Fatigue item FATEXP42")
```

Once we evaluate Formula \@ref(eq:Probability) for all levels of theta (e.g., -4 to 4) and for all item calibrations statistics provided in Table \@ref(tab:TableOfCalibrations), we can create a set of probability curves that represent each item's response options. Figure \@ref(fig:FATEXP42ItemCharacteristicCurves) shows an example of how the response options of FATEXP42 are ordered across level of theta (level of fatigue), with response option *Not at all* having higher probabilities at lower levels of theta (lower fatigue), and response option *Very much* having higher probabilities at higher levels of theta (higher fatigue).

```{r FATEXP42ItemCharacteristicCurves, dev="png", fig.path="Figures/", fig.cap="Response option probabilities across theta for PROMIS Fatigue item FATEXP42, *In the past 7 days, how much mental energy did you have on average?*", fig.width=8, fig.height=4, dpi=200}

# This R Markdown chunk calculates and plots the response option probabilities for PROMIS Fatigue item FATEXP42

  # ni: Number of items = 1 (only FATEXP42)
    ni=1

  # NCAT: Number of response categories in FATEXP42
    NCAT=Items$Fatigue$FATEXP42$NCAT
    
  # maxCat: Maximum number of response option categories = number of response option categories in FATEXP42
    maxCat=NCAT
    
  # DISC: discrimination item calibration statistic, referred to as "a"
    DISC=Items$Fatigue$FATEXP42$Calibrations[,"a"];
    
  # CB: threshold item calibration statistics, referred to as "cb1" to "cb4"
    CB=Items$Fatigue$FATEXP42$Calibrations[,paste0("cb",1:(maxCat-1))];
    
  # pp: 3d array of response option probabilities for FATEXP42,
    # calculated with prep.prob() function and
    # above variables (e.g., NCAT, DISC, CB, ni)
    pp<-prep.prob();
    
  # label the dimensions of the pp array with
    # 1) Theta levels (rounded two digits)
    # 2) the name of the one item, FATEXP42
    # 3) the response option labels (e.g., Never, Sometimes, Always)
    dimnames(pp)=list(
     c(round(theta,1)),
     c("FATEXP42"),
     names(Items$Fatigue$FATEXP42$ResponseOptions))

  # Set the plotting margin parameters to accommodate the axis labels 
    par(mar=c(4,4,2,2))

  # Create the empty plotting space for the FATEXP42's
    # response option probability curves
    plot(NA, type="n", family="Times New Roman",
         xaxt="n", xlab="Theta", xlim=c(0, dim(pp)[1]), #Theta Quadrature on the X axis
         ylab="Probability", ylim=c(0, 1)) #Probabilities, 0-1 on the Y axis
    
  # custom X axis labels for whole numbers in the theta quadrature
    # without this, you get x axis labels 1-81 from length of the quadrature
    axis(1, at=which(!as.numeric(dimnames(pp)[[1]])%%1), labels=Theta_axis_lab, family="Times New Roman")

  # for each response option, "i" (i in 1:NCAT)...
    for(i in 1:NCAT){
    # plot response option, "i", using Colors and LineType & LineWidth vectors 
      lines(pp[,1,i], col=Colors[i], lty=LineTypes[i], lwd=LineWidth[i] )}
    
  # add response option text for first response option 
    # near max response option probability
    text(family="Times New Roman",
        x=which.max(pp[,1,1]),
        y=max(pp[,1,1]), 
        labels=names(pp[1,1,])[1], 
        adj=c(0,3.5))
    
  # add response option text for second response option 
    # near max response option probability
    text(family="Times New Roman",
        x=which.max(pp[,1,2]),
        y=max(pp[,1,2]), 
        labels=names(pp[1,1,])[2], 
        pos=3)

  # add response option text for third response option 
    # near max response option probability
    text(family="Times New Roman",
        x=which.max(pp[,1,3]),
        y=max(pp[,1,3]), 
        labels=names(pp[1,1,])[3], 
        pos=3)

  # add response option text for fourth response option 
    # near max response option probability    
    text(family="Times New Roman",
        x=which.max(pp[,1,4]),
        y=max(pp[,1,4]), 
        labels=names(pp[1,1,])[4], 
        pos=3)

  # add response option text for fifth response option 
    # near max response option probability    
    text(family="Times New Roman",
        x=which.max(pp[,1,5]),
        y=max(pp[,1,5]), 
        labels=names(pp[1,1,])[5], 
        adj=c(1,-0.5))

```
  
  
This tutorial demonstrates how PROMIS measures are scored using graphical representations of probability curves, such as those in Figure \@ref(fig:FATEXP42ItemCharacteristicCurves). To aid interpretation, these probability curves are plotted with consistent formatting styles, detailed in Table \@ref(tab:TableOfLineColors). All response option probability curves are plotted with a dotted, dashed or dash-dotted line. The first and second threshold probability curves are plotted with different colored solid lines. The prior and posterior probability curves are plotted with different colored and weighted solid lines. All colors used in figures were selected from the *colorBlindness* package in R by @colorBlindness.

```{r TableOfLineColors}
# This R Markdown chunk creates a Kable table of line styles (i.e., colors & patterns) that are used across the tutorial

# Labels: vector containing the meaning of the line styles 
Labels=c(
  "First Response Option or Pattern",
  "Second Response Option or Pattern",
  "Third Response Option or Pattern",
  "Fourth Response Option",
  "Fifth Response Option",
  "First Threshold",
  "Second Threshold",
  "Prior",
  "Posterior",
  "Posterior Standard Deviation")

# create a set of images that reflect the line styles used across the tutorial graphs
# for each label, "i", (i in 1:length(Labels))...
for(i in 1:length(Labels)){
  # create a PNG file in a folder labeled "Figures"
  png(paste0(paste0(getwd(), "/Figures/"), Labels[i], ".png"), units="in", height=0.1, width=0.25, res=500)
  # set plotting margins to zero
  par(mar=c(0,0,0,0))
  # create a new empty plotting space
  plot.new()
  # size the plotting window
  plot.window(ylim=c(0,10),xlim=c(0,25))
  # for all labels that are not the Posterior Standard Deviation, draw a line, matching the linewidth, style and colors
  if(Labels[i]!="Posterior Standard Deviation"){abline(h=5, lty=LineTypes[i], lwd=LineWidth[i], col=Colors[i])}
  # for the posterior standard deviation, draw a gray shaded rectangle
  else{rect(0,0,25,10, col="gray", density = 75)}
  # save the image
  dev.off()
}

# create a Kable table of line style labels and images, created above ^
knitr::kable(data.frame(
  "Style"=paste0('![](',getwd(),'/Figures/', Labels, '.png)'),
  "Representation"=Labels
  ),
 caption="Table of Line Styles and their Representation")
```


Figure \@ref(fig:PlotProbPFA51) uses PROMIS Physical Function item PFA51 (*Are you able to sit on the edge of a bed?*) to provide a more detailed example of how Formula \@ref(eq:Probability) and item calibration statistics can be used to generate a set of probabilities and plot what are referred to as item characteristic curves. The top two graphs of Figure \@ref(fig:PlotProbPFA51) show the probability curves associated with the first two thresholds. The first threshold, cb1, is represented by a solid yellow line orange line and the second threshold, cb2, is represented by a solid dark green line.  

The center left plot of Figure \@ref(fig:PlotProbPFA51) shows how a single probability curve (dotted blue line) can be calculated by subtracting the first threshold (cb1, yellow line) from the second threshold (cb2, solid dark green line). At the theta level of -3.3 the probability difference between first threshold (cb1, solid yellow line) and second threshold (cb2, solid dark green line) is 0.36 and the probability of an individual with -3.3 level of physical functioning selecting the second response option (dotted blue line) is 0.36. The calculated dotted blue probability curve represents the probability of an individual selecting the second response option of PFA51 (*With much difficulty*) across the spectrum of physical functioning (theta).

The center right plot of Figure \@ref(fig:PlotProbPFA51) shows how the probability curves for the two extreme response categories, *Without any difficulty* and *Unable to do*, are calculated by subtracting the lowest threshold (cb1) probabilities from 1 and subtracting the highest threshold (cb4) probabilities by 0. Subtracting the highest and lowest thresholds by 1 and 0 anchors the extreme response option probabilities at their limits, either certainty (1) or impossibility (0). Subtracting the lowest threshold (cb1, solid yellow line) by 1 'flips' the probabilities to create the first response option (*Unable to do*)  probability curve, represented by a dashed purple line. Subtracting the highest threshold (cb4, pink line) by 0 means that the probabilities of the response option associated with the highest level of theta (*Without any difficulty*) are the same as the response probabilities of the highest threshold (cb4). The dot-dashed pink line represents both cb4 threshold probabilities and *Without any difficulty* response option probabilities.  

The plot at the bottom of Figure \@ref(fig:PlotProbPFA51) shows the probability curves for all five response options of PFA51. The calibration statistics for PFA51 and other PROMIS Physical Function items mentioned in this work can be found in the first Table of @Rose2014PF. These response option probabilities are the building blocks of IRT scoring in PROMIS.  
  
```{r PlotProbPFA51, dev="png", fig.path="Figures/", fig.cap="Calculation of response option probabilities across theta using PROMIS Physical Function item PFA51", fig.width=8, fig.height=6, dpi=200}

# This R Markdown chunk calculates the threshold probabilities and
  # response option probabilities for PROMIS Physical Function item PFA51

  # ni: Number of items = 1 (only PFA51)
  ni=1
  # NCAT: Number of response categories in PFA51
  NCAT=Items$`Physical Function`$PFA51$NCAT
  # DISC: discrimination item calibration statistic, referred to as "a"
  DISC=Items$`Physical Function`$PFA51$Calibrations[,"a"]
  # CB: threshold item calibration statistics, referred to as "cb"
  CB=Items$`Physical Function`$PFA51$Calibrations[,paste0("cb",1:4)]

  # create a 2d matrix of zeros with
    # matrix dimensions of
    # 1) nq: length of theta quadrature
    # 2) NCAT[i]+1: number of response options for the select item plus one
  ps<-matrix(0,nq,NCAT+1);

  # Create probability boundaries of 1 (certainty) and 0 (impossibility)
    # This will be used for later subtraction of threshold probabilities to create
    # extreme response option probabilities
  ps[,1]<-1; ps[,NCAT+1]<-0;

  # For all item calibration thresholds, "k" (k in 1:(NCAT[i]-1) in select item "i"...   
  for (k in 1:(NCAT-1)) {
      # between 1 and 0 (above), populate the matrix with probabilities
      # from each item calibration threshold, k, for select item, i
      # using the grade response model formula
        ps[,k+1]<-1/(1+exp(-1*DISC*(theta-CB[[k]])));
    }

# Setting for graphing, Times New Roman font
  par(cex.main=1, family="Times New Roman")
# Layout creates combines multiple plots in one figure
  layout(matrix(c(1:4,5,5), nrow=3, ncol=2, byrow = TRUE))

# top left plot - cb1 threshold probabilities
  plot(ps[,2], #ps[,2]: cb1 threshold probabilities - ps[,1] is all 1's
    main=paste(sep="\n",
    "PFA51",Items$`Physical Function`$PFA51$Stem,
    "First threshold, cb1"),
    ylab="Probability", ylim=c(0,1),
    type="l", col=Colors[6],
    xaxt="n", yaxt="n", xlab="Theta")
  axis(1, at=which(theta %in% seq(minTheta,maxTheta,1)),  labels=Theta_axis_lab, family="Times New Roman")
  
  # Probability axis tickmarks every 50%
    axis(2, cex.axis=0.75, at=seq(0,1,0.5), cex=0.75, family="Times New Roman")

# top right plot - cb2 threshold probabilities
  plot(ps[,3], #ps[,3]: cb2 threshold probabilities
  main=paste(sep="\n",
      "PFA51",Items$`Physical Function`$PFA51$Stem,
      "Second threshold, cb2"),
    ylab="Probability", ylim=c(0,1),
    type="l", col=Colors[7],
    xaxt="n", yaxt="n", xlab="Theta")
  axis(1, at=which(theta %in% seq(minTheta,maxTheta,1)),  labels=Theta_axis_lab, family="Times New Roman")
  
  # Probability axis tickmarks every 50%
    axis(2, cex.axis=0.75, at=seq(0,1,0.5), cex=0.75, family="Times New Roman")


# Center Left plot, difference between cb1 & cb2
  plot(ps[,2], #ps[,2]: cb1 threshold probabilities
    main=paste(sep="\n",
      "PFA51",Items$`Physical Function`$PFA51$Stem,
      "Difference between thresholds "),
    ylab="Probability", ylim=c(0,1),
    type="l", col=Colors[6],
    xaxt="n", yaxt="n", xlab="Theta")
    Theta_axis_lab=theta[theta%%1==0]
  lines(ps[,3], col=Colors[7]) #ps[,3]: cb2 threshold probabilities
  lines((ps[,2]-ps[,3]),col=Colors[2], lty=LineTypes[2]) #the difference between threshold cb1 (ps[,2]) and threshold cb2 (ps[,3]) is the probability of the second response option
  axis(1, at=which(theta %in% seq(minTheta,maxTheta,1)),  labels=Theta_axis_lab, family="Times New Roman")
  
  # Probability axis tickmarks every 50%
    axis(2, cex.axis=0.75, at=seq(0,1,0.5), cex=0.75, family="Times New Roman")

  # Line segment, brace and text representing the probability difference
    # between threshold cb1 & threshold cb2 at theta -3.3
  segments(x0=8, x1=8, y0=0 , y1=(ps[8,2]-ps[8,3]), col="darkgray" )
  CurlyBraces(9, (ps[8,2]-ps[8,3])/2, (ps[8,2]-ps[8,3]), pos=1, direction=1, col="darkgray", size=15)
  text(x=20, y=(ps[8,2]-ps[8,3])/2, labels=round(ps[8,2]-ps[8,3],2), col="darkgray", family="Times New Roman" )

  # Line segment, brace and text representing the second response option probability at theta -3.3
  segments(x0=8, x1=8, y0=ps[8,2], y1=ps[8,3], col="lightblue3" )
  CurlyBraces(9, (ps[8,2]-ps[8,3])/2+ps[8,3], (ps[8,2]-ps[8,3]), pos=1, direction=1, col="lightblue3", size=15)
  text(x=20, y=(ps[8,2]-ps[8,3])/2+ps[8,3], labels=round((ps[8,2]-ps[8,3]),2), col="lightblue3", family="Times New Roman" )
  text(x=5, y=ps[8,2], labels=theta[8], adj=c(0.75,0.5))

  # Center right plot showing the calculation of extreme response option probabilities
  plot(ps[,2],  # ps[,2]: cb1 threshold probabilities
    col=Colors[6], type="l",
    main=paste(sep="\n",
      "PFA51",Items$`Physical Function`$PFA51$Stem,
      "Extreme response option probability calculation"),
    ylim=c(0,1), ylab="Probability",
    xlim=c(1,length(theta)), xaxt="n", yaxt="n", xlab="Theta")
  lines(1-ps[,2],col=Colors[1], lty=LineTypes[1]) # First response probabilities are 1 minus the probabilities of cb1 (ps[,2])
  lines(ps[,5]-0,col=Colors[5], lty=LineTypes[5]) # Last response probabilities are the probabilities of cb4 (ps[,5]) minus zero
  axis(1, at=which(theta %in% seq(minTheta,maxTheta,1)),  labels=Theta_axis_lab, family="Times New Roman")
  
  # Probability axis tickmarks every 50%
  axis(2, cex.axis=0.75, at=seq(0,1,0.5), cex=0.75, family="Times New Roman")

  # Arrows to show that how the cb1 probability curve is 'flipped' to make the first response option probability curve
  arrows(x0=1, x1=1, y0=0.7, y1=0.3, code=1, length=0.05)
  arrows(x0=10, x1=10, y0=0.3, y1=0.7, code=1, length=0.05)

  # Bottom right and left plot, all response probability curves
  plot(NA,type="n", 
    main=paste(sep="\n",
      "PFA51",Items$`Physical Function`$PFA51$Stem,
      "All response option probabilities"),
    ylim=c(0,1), ylab="Probability",
    xlim=c(1,length(theta)), xaxt="n", yaxt="n", xlab="Theta")
  for(k in 1:NCAT){lines((ps[,k]-ps[,k+1]), col=Colors[k], lty=LineTypes[k])}
  axis(1, at=which(theta %in% seq(minTheta,maxTheta,1)),  labels=Theta_axis_lab, family="Times New Roman")
  
  
  # Probability axis tickmarks every 50%
    axis(2, cex.axis=0.75, at=seq(0,1,0.5), cex=0.75, family="Times New Roman")

```
    
   
    
# Expected A Posteriori Scoring {.unnumbered}

## How Do We Go From IRT Probabilities to Scores? {.unnumbered}

IRT provides a probability-based model which is very useful for the quantitative evaluation of item- and scale-level characteristics in survey development, but we can also use IRT to find a point estimate of an individual's position on the theta spectrum. In other words, we can score individuals on the latent trait. PROMIS scores are reported on the "T-score" metric, which is a linear transformation of theta, as shown in Formula \@ref(eq:Tscore). This tutorial reports scores as either theta or T-scores, with the understanding that they are linearly related. 

\begin{equation}
T-score = (theta*10)+50
(\#eq:Tscore)
\end{equation}

```{r RespCatProbThetaSecondOnlyCalc}

 # This R Markdown chunk find the maximum probability and the probabilities associated with the second response option "A little bit" 
  # of Fatigue item FATEXP42. The pp object with response option probabilities is reused from a previous example,
  # coded and referenced above. This is broken out from the graph so that it maxprob and maxprob theta can be referenced
  # in the text, see `r maxprobtheta` below.
    
    # maxprob: max probability of the second response of FATEXP42
      maxprob=max(pp[,"FATEXP42","A little bit"])

    # maxprobtheta: the theta associated with the maximum probability point of the second response of FATEXP42 
      maxprobtheta=as.numeric(dimnames(pp)[[1]][[which.max(pp[,"FATEXP42","A little bit"])]])
    
    # maxprobthetaindex: the theta quadrature 'index' (1:81) related to maxprobtheta 
      maxprobthetaindex=which(names(pp[,"FATEXP42","A little bit"])==maxprobtheta)

```


As a score calculation example, we will again use PROMIS Fatigue item FATEXP42 (*In the past 7 days, how much mental energy did you have on average?*).
See item response option probability curve for the second response option (*A little bit*) in Figure \@ref(fig:RespCatProbThetaSecondOnly).
A logical IRT score is the most probable level of theta, also known as the maximum likelihood of theta.
Using this method, an individual that selected the second response option of FATEXP42 would be assigned a maximum likelihood score of `r maxprobtheta` or T-score of `r (maxprobtheta*10+50)`, as shown in Figure \@ref(fig:RespCatProbThetaSecondOnly).

```{r RespCatProbThetaSecondOnly, dev="png", fig.path="Figures/", fig.cap="Response option probabilities across theta for PROMIS Fatigue item FATEXP42 *A little bit* response option only", fig.width=3, fig.height=3, dpi=200}

 # This R Markdown chunk calculates and renders a plot of the probability  curve of the second response option of FATEXP42, "A little bit" 
  # and plots the point of maximum likelihood and it's associated level of theta.

   # Set the plotting margins to include the plot axes
   par(mar=c(4,4,2,2))

    # Create the plotting space
    plot(NA, type="n", family="Times New Roman",
         xaxt="n", yaxt="n", xlab="Theta", xlim=c(0, dim(pp)[1]),
         ylab="Probability", ylim=c(0, 1))
    
    # Plot a custom axis for the theta quadrature
    axis(1, at=which(theta %in% seq(minTheta,maxTheta,1)),  labels=Theta_axis_lab, family="Times New Roman")
    
    # Probability axis tickmarks every 50%
    axis(2, cex.axis=1, at=seq(0,1,0.5), cex=1, family="Times New Roman")
    
    # Plot the probability curve of of the second response option of FATEXP42 
    lines(pp[,"FATEXP42","A little bit"], col=Colors[2], lty=LineTypes[2])
    
    # Draw a line segment indicating the point of maximum probability
    segments(x0=maxprobthetaindex, x1=maxprobthetaindex, y0=maxprob, y1=0)

    # Text of the theta level associated with the maximum probability point, located above the curve
    text(x=maxprobthetaindex, y=maxprob, labels=maxprobtheta, pos=3, family="Times New Roman")


```

This simple example has two problems, however.
The first problem comes from a practical issue in measurement and the second stems from mathematical limitations.
The practical measurement issue occurs when respondents select the absolute highest or lowest response option in an item (e.g., *Never* or *Always*). Using another fatigue item as an example, in FATEXP29 (*In the past 7 days, how often did you feel totally drained?*) the extreme response of *Never* is likely selected by people with very different experiences of fatigue: *Never* would be selected a respondent with low-level fatigue (e.g., feels slightly, but not totally drained over the past week), *Never* would be selected by a respondent who didn't experience fatigue (e.g., didn't feel drained at all over the past week) and *Never* would be selected by a respondent who had an unusually high energy over the past week. While the extreme response option of *Never* is selected by all three respondents for this item, we can be more certain that respondents with even less fatigue (or more energy) are increasingly likely to pick the *Never* response option.  

This is also true for the other extreme response option, *Always*. A response of *Always* is likely to be selected by a respondent who just had a totally draining week, by a respondent who had a totally draining month, or by a respondent who had a totally draining year. The inability of an item or scale to distinguish between extreme levels is a measurement property known as the "floor" and "ceiling" effect, @APADictionary. The response probability curves of the extreme responses options show these floor and ceiling effects (Figure \@ref(fig:RespCatProbThetaExtremeOnly)). Probabilities of these extreme responses categories are monotonic, meaning they have a constantly increasing probability of being selected with increasingly extreme levels of theta, and there is no single point of maximum likelihood for us to use as a score.   

The second problem related to mathematical limitations is the infinite space that we assume exists for the latent trait. All response option probability curves are asymptotic, meaning the probability curves expand over an infinite range of theta and never reach probability values of either 0 or 1. It is mathematically complex and computationally costly to perform calculations in an infinite space.

```{r RespCatProbThetaExtremeOnly, dev="png", fig.path="Figures/", fig.cap="Response option probabilities across theta for PROMIS Fatigue item FATEXP42, *Not at all* and *Very much* extreme responses options only", fig.width=3, fig.height=3, dpi=200}

 # This R Markdown chunk plots the probability curve of the extreme response option of FATEXP42, "Not at all" and "Very much" 
    
    # Set the margins of the plot to include the plot axes
    par(mar=c(4,4,2,2))

    # Create the plotting space
    plot(NA, type="n", family="Times New Roman",
     xaxt="n", yaxt="n", xlab="Theta", xlim=c(0, dim(pp)[1]),
     ylab="Probability", ylim=c(0, 1))

    # Plot a custom axis for the theta quadrature
    axis(1, at=which(theta %in% seq(minTheta,maxTheta,1)),  labels=Theta_axis_lab, family="Times New Roman")
      
    # Probability axis tickmarks every 50%
    axis(2, cex.axis=1, at=seq(0,1,0.5), cex=1, family="Times New Roman")
    
    # Draw the probability curves for FATEXP42's extreme probability curves, "Not at all" and "Very much"
    lines(pp[,"FATEXP42","Not at all"], col=Colors[1], lty=LineTypes[1])
    lines(pp[,"FATEXP42","Very much"], col=Colors[5], lty=LineTypes[5])

```


To solve these two problems, we use a scoring mechanism called "Expected A Posteriori" (EAP) scoring, [@Bock1982EAP; @Bock1981MMLE]. This form of scoring works by imposing constraints on how we calculate probabilities.
The first constraint comes from limiting the infinite theta space to a "quadrature", which can be visualized in Figure \@ref(fig:ThetaQuadratureLine) as a set of evenly spaced points on a number line or x axis between two bounds.
PROMIS uses boundaries of -4 theta to 4 theta or (T-scores of 10-90), with 0.1 theta increments (1 T-score point).
This quadrature was carefully chosen to cover the overwhelming majority of respondents: theta can be interpreted as standard deviations of the population, and we can assume that a range of -4 to 4 theta encompasses 99.994% of people.
As will be demonstrated later, the quadrature allows us to use simple multiplication instead of integral calculus to obtain a maximum likelihood point estimate of our probability sets.

```{r ThetaQuadratureLine, dev="png", fig.path="Figures/", fig.cap="Theta quadrature as number line", fig.width=8, fig.height=2.5, dpi=200}

# This R Markdown chunk plots the theta quadrature as a number line 

# Create an empty plotting space
  plot(NA, type="n",xaxt="n", yaxt="n", xlab="", ylab="", bty="n", 
       ylim=c(-0.85,0.25), xlim=c(min(theta)-1,max(theta)+1), mar=c(0,0,0,0))

# Draw an double ended arrow
  arrows(y0=0,y1=0,x0=min(theta)-1,x1=max(theta)+1, code=3, length = 0.175)

# Cycle through every increment, "i" in the theta quadrature "theta"...
  for(i in theta){
      # draw major tick marks at quarter increments of theta
        if(!i%%0.5){segments(y0=-0.25,y1=0.25,x0=i,x1=i)}
      # draw minor tick marks at every other increment of theta
        else{segments(y0=-0.1,y1=0.1,x0=i,x1=i)}
      # insert theta numbers at whole numbers of theta
        if(!i%%1){text(i,-0.75,i,family="Times New Roman")}}
  
# insert infinity and negative infinity symbols at the extremities of the number line
  text( min(theta)-0.7,-0.8,expression(-infinity), cex=1.75, family="Times New Roman")
  text( max(theta)+0.9,-0.75,expression(infinity), cex=1.75, family="Times New Roman")

```

The quadrature does not alleviate all of the problems of maximum likelihood scoring with extreme responses, however. The quadrature stops the constant growth of the extreme response option's probability curve at its limits (-4 to 4), which means that an extreme response option's 'maximum likelihood' theta score will be tied to the quadrature limits. Expanding or shrinking the limits of the quadrature (e.g., -6 to 6 or -2 to 2) will increase or decrease the scores of extreme response options, which is a validity problem for scores. An individual could receive different theta scores unrelated any real difference in the latent trait.   

EAP scoring uses a "prior" in the calculation of scores to address this problem.
Generally, a prior is a bayesian concept that refers to our best guess of an individual's theta score before they've selected a response option, @APADictionary. The EAP scoring prior used in PROMIS is a normal distribution which reflects the population mean (Î¼=0) and standard deviation (Ï=1). It is a reasonable assumption that any individual is a member of the population.

After multiplication by the prior probability curve, the extreme response probability curve is reshaped, repositioned and called the "posterior probability". The new posterior probability curve is pulled back from the quadrature limit and is no longer monotonic: instead it looks like the normal curve of the prior. The amount of the lateral repositioning of the posterior (and movement of the maximum likelihood score) away from the quadrature limit is a function of the area under the curve of the original extreme response option probability and the area under the curve of the prior.

Figure \@ref(fig:RespCatProbThetaExtremePriorwMath) shows a graphical example of the new posterior curve. In Figure 6, the dashed purple line represents the response probabilities from FATEXP42âs extreme response option (*Not at all*), the solid green line represents the prior probability curve, and the bold solid orange line represents the new posterior probability curve with a maximum probability of -0.87. The posterior (bold solid orange) can be visualized as 'splitting the difference' between the probability curves of the extreme response option (dashed purple) and the prior (solid green).

```{r RespCatProbThetaExtremePriorwMath, dev="png", fig.path="Figures/", fig.cap="Response option probabilities across theta for PROMIS Fatigue item FATEXP42 *Not at all* extreme response option only, with math", fig.width=8, fig.height=4, dpi=200}

    
 # This R Markdown chunk plots three probability curves- the extreme response option of FATEXP42, "Not at all", 
  # the prior probability curve and the posterior probability curve- along with it's point of maximum likelihood.
  # Below the graphs there is a breakdown of how the theta quadrature allows us to perform simple multiplication
  # of the response probability curve with the prior probability curve across all levels of theta to calculate
  # the posterior probability curve. 

# Set the plotting margins
  par(mar=c(1,4,1,1))

# Create an empty plotting space
  plot(NA, type="n", bty="n", xpd=TRUE, ann=FALSE,
       xaxt="n", xlim=c(-1, dim(pp)[1]),
       yaxt="n", ylim=c(-3, 1))
# Theta quadrature axis in the center of the graph space- position=0
  axis(1, pos=0, cex.axis=1, at=which(theta %in% seq(minTheta,maxTheta,1)), labels=Theta_axis_lab, family="Times New Roman") 

# Probability axis tickmarks every 50%
  axis(2, pos=which.min(as.numeric(dimnames(pp)[[1]])), cex.axis=1, at=seq(0,1,0.5), cex=1, family="Times New Roman")

# Plot the probability curve for the FATEXP42's extreme response option "Not at all"
  lines(pp[,"FATEXP42","Not at all"], col=Colors[1], lty=LineTypes[1])

# Plot the probability curve for the normal prior
  lines(prior,col=Colors["Prior"], lty=LineTypes["Prior"], lwd=LineWidth["Prior"])

# Calculate the posterior probability by multiplying the response probability by the prior probability 
  posterior=pp[,"FATEXP42","Not at all"]*prior

# Plot the posterior probability
  lines(posterior,col=Colors["Posterior"], lty=LineTypes["Posterior"], lwd=LineWidth["Posterior"])

# Calculate the theta weighted posterior by posterior probability by the theta quadrature
  thetaweightedposterior=posterior*theta

# Calculate the theta score by dividing the sum of theta weighted posterior probabilities
  # by the sum of the posterior probabilities
  thetascore=sum(thetaweightedposterior)/sum(posterior)

# Find the index of the thetascore in terms of the length of the theta quadrature
  thetascoreindex=which(round(theta,1)==round(as.numeric(thetascore),1))

# Print the thetascore on the graph space and draw an arrow pointing to the point of maximum likelihood of the posterior
  text(x=thetascoreindex, y=0.5, adj=c(0.5,-0.5), labels=round(thetascore,2), family="Times New Roman")
  arrows(x0=thetascoreindex, x1=thetascoreindex, y0=0.5, y1=max(posterior)+0.05, length=0.05)

# Print the word "Theta" as the X axis label, in the center of the graph space but below the plot
  text(length(dimnames(pp)[[1]])/2,-0.6, cex=1, "Theta", family="Times New Roman")
# Print the word "Probability" as the Y axis label, in the center of the graph space but left of the plot
  mtext("Probability", side=2, line=1.5, at=0.5, cex=1, family="Times New Roman")

# Draw a horizontal line segment to represent the theta quadrature
  segments(y0=-1,y1=-1,x0=which.min(dimnames(pp)[[1]]),x1=which.max(dimnames(pp)[[1]]))

# For each theta increment, "i", in the theta quadrature...
  for(i in as.numeric(dimnames(pp)[[1]])){
  
  # j: index of the theta increment, i,  in the length of the theta quadrature, 1:81
    j=which(as.numeric(dimnames(pp)[[1]])==i)
  
  # Draw major tickmarks on 0.5 theta increments and minor tickmarks on all other increments
    if(!i%%0.5){segments(y0=-0.875,y1=-1.125,x0=j,x1=j)}
    else{segments(y0=-1.05,y1=-0.95,x0=j,x1=j)}
  
  # At all whole number increments of theta...
    if(!i%%1){
      # Print theta quadrature level
        text(j,-1.5,i, cex=1, family="Times New Roman")
      # Print response probability 
        text(j,-2,format(round(pp[j,1,"Not at all"],3),nsmall=3), cex=1, family="Times New Roman",
          col=Colors[1])
      # Print an "x" as a multiplication sign
        text(j,-2.25, "x", cex=1, family="Times New Roman")
      # Print prior probability
        text(j,-2.5,format(round(prior[j],3),nsmall=3), cex=1, col=Colors["Prior"], family="Times New Roman")
      # Print an equals sign 
        text(j,-2.75, "=", cex=1, family="Times New Roman")
      # Print the posterior probability
        text(j,-3,format(round(posterior[j],3),nsmall=3), cex=1, col=Colors["Posterior"],family="Times New Roman")}
  
  # At non-whole number 0.5 increments of theta print "..."
    if(!i%%0.5 & i%%1){
      text(j,-1.5,adj=c(0.5,0.6),"...", cex=1, family="Times New Roman")
      text(j,-2,adj=c(0.5,0.6),"...", cex=1, family="Times New Roman", col=Colors[1])
      text(j,-2.5,adj=c(0.5,0.6),"...", cex=1, col=Colors["Prior"], family="Times New Roman")
      text(j,-3,adj=c(0.5,0.6),"...", cex=1, col=Colors["Posterior"], family="Times New Roman")}
  }
  
  # In the plot margin, print labels for the theta quadrature, response, prior and posterior probabilities
    mtext("Theta \n Quad. ", side=2, line=0.5, at=-1.5, cex=1, las=2, family="Times New Roman")
    mtext("Response \n Prob. ", side=2, line=0.5, at=-2, cex=1, las=2, family="Times New Roman", col=Colors[1])
    mtext("Prior \n Prob.", side=2, line=0.5, at=-2.5, cex=1, las=2, col=Colors["Prior"], family="Times New Roman")
    mtext("Posterior \n Prob. ", side=2, line=0.5, at=-3, cex=1, las=2, col=Colors["Posterior"], family="Times New Roman")

```

The bottom half of Figure \@ref(fig:RespCatProbThetaExtremePriorwMath) shows the calculation of the posterior probability curve.
At each increment on the theta quadrature ( `r minTheta` to `r maxTheta` by increments of `r inc`), the response option probability is multiplied by the prior probability.
For example, at a theta of -1, the response probability of `r round(pp[which(as.numeric(dimnames(pp)[[1]])==-1),1,"Not at all"],3)` is multiplied by a prior probability of `r round(prior[which(as.numeric(dimnames(pp)[[1]])==-1)],3)` , which equals a posterior probability of `r round(posterior[which(as.numeric(dimnames(pp)[[1]])==-1)],3)`.
The size of the posterior probabilies are shrunk due to the multiplication of decimals, but we are only concerned with the location of the maximum likelihood point estimate that we'll use as an EAP score. Without the theta quadrature, integral calculus would be required to multiply the prior and the response option probability curves.

Figure \@ref(fig:ThetaCalcPosteriorProbMath) further demonstrates the method for calculating a single theta score from posterior probabilities across the theta quadrature.
The quadrature again allows us to use simple multiplication in lieu of calculus, by multiplying posterior probabilities at each theta increment by their corresponding theta level to create a set of theta weighted posterior probabilities, e.g., theta of -2 multiplied by a posterior probability of `r round(posterior["-2"],3)` equals a weighted probability of `r round(posterior["-2"],3)*-2`. Dividing the sum of the weighted posterior probabilities (`r round(sum(thetaweightedposterior),2)`) by the sum of the posterior probabilities (`r round(sum(posterior),2)`) gives us the final theta estimate (`r round(sum(thetaweightedposterior)/sum(posterior),2)`).



```{r ThetaCalcPosteriorProbMath, dev="png", fig.path="Figures/", fig.cap="Calculation of theta scores from  posterior probabilities across the theta quadrature for PROMIS Fatigue item FATEXP42, *Not at all* response option only", fig.width=8, fig.height=4, dpi=200}

# This R Markdown chunk creates a figure showing how theta weighted posterior probabilities are used to generate theta scores

  # Set plotting margins
  par(mar=c(1,4,1,1))

  # Create an empty plot space
    plot(NA, type="n", bty="n", xpd=TRUE, ann=FALSE, family="Times New Roman",
         xaxt="n", xlim=c(-1, dim(pp)[1]),
         yaxt="n", ylim=c(-1, 3.125))

  # Draw a horizontal line segment to represent the theta quadrature
    segments(y0=3,y1=3,x0=which.min(dimnames(pp)[[1]]),x1=which.max(dimnames(pp)[[1]]))

  # For each theta increment, "i", in the theta quadrature...
    for(i in as.numeric(dimnames(pp)[[1]])){
  
  # j: index of the theta increment, i,  in the length of the theta quadrature, 1:81
    j=which(as.numeric(dimnames(pp)[[1]])==i)
 
  # Draw major tickmarks on 0.5 theta increments and minor tickmarks on all other increments
    if(!i%%0.5){segments(y0=2.875,y1=3.125,x0=j,x1=j)}
    else{segments(y0=3.05,y1=2.95,x0=j,x1=j)}
  
  # At all whole number increments of theta...
    if(!i%%1){
      # Print theta quadrature level
        text(j, 2.5,i, cex=1, family="Times New Roman")
      # Print response probability 
        text(j, 2.125, "x", cex=1, family="Times New Roman")
      # Print an "x" as a multiplication sign
        text(j, 1.75,format(round(posterior[j],3),nsmall=3), cex=1, col=Colors["Posterior"], family="Times New Roman")
      # Print prior probability
        text(j, 1.375, "=", cex=1, family="Times New Roman")
      # Print an equals sign 
        text(j, 1,format(round(thetaweightedposterior[j],3),nsmall=3), cex=1, col=Colors["ThetaWeightedPosterior"], family="Times New Roman")
      # Print the posterior probability
        text(j, -1,format(round(posterior[j],3),nsmall=3), cex=1, col=Colors["Posterior"], family="Times New Roman")}
    
  # At non-whole number 0.5 increments of theta print "..."
    if(!i%%0.5 & i%%1){
      text(j, 2.5,adj=c(0.5,0.6),"...", cex=1, family="Times New Roman")
      text(j, 1.75,adj=c(0.5,0.6),"...", cex=1, col=Colors["Posterior"], family="Times New Roman")
      text(j, 1,adj=c(0.5,0.6),"...", cex=1, col=Colors["ThetaWeightedPosterior"], family="Times New Roman")
      text(j, -1,adj=c(0.5,0.6),"...", cex=1, col=Colors["Posterior"], family="Times New Roman")}
    }

  # In the plot margin, print labels for the theta quadrature, response, prior and posterior probabilities
    mtext("Theta \n Quad. ", side=2, line=0.5, at=2.5, cex=1, las=2, family="Times New Roman")
    mtext("Posterior \n Prob. ", side=2, line=0.5, at=1.75, cex=1, las=2, col=Colors["Posterior"], family="Times New Roman")
    mtext("Weighted \n Posterior \n Prob. ", side=2, line=0.5, at=1, cex=1, las=2, col=Colors["ThetaWeightedPosterior"], family="Times New Roman")
    mtext("Posterior \n Prob. ", side=2, line=0.5, at=-1, cex=1, las=2, col=Colors["Posterior"], family="Times New Roman")
  
  # Draw top curly brace, indicating the summation of theta weighted posterior probabilities
    CurlyBraces(0.75, 41, 80, pos=2, direction=2, col=Colors["ThetaWeightedPosterior"])

  # Print "Sum = " for numerator and sum of theta-weighted posterior
    text(41-4, 0.15, pos=2, cex=1, "Sum =", family="Times New Roman")
    text(41, 0.15, adj=c(0.5,0.5), cex=1, round(sum(thetaweightedposterior),2), family="Times New Roman")

  # Draw a division line between numerator and denominator
    segments(x0=41-4,x1=41+4,y0=0,y1=0)

  # Print "Sum = " for the denominator and sum of the posterior
    text(41-4, -0.15, pos=2, cex=1, "Sum =", family="Times New Roman")
    text(41, -0.15, adj=c(0.5,0.5), cex=1, round(sum(posterior),2), family="Times New Roman")

  # Print the score after division of the sum of theta-weighted posterior and sum of posterior 
    text(41+4, 0, pos=4, font=2, cex=1, paste(" = ",round(sum(thetaweightedposterior)/sum(posterior),2), "Theta"), family="Times New Roman")  

  # Draw bottom curly brace, indicating summation of posterior 
    CurlyBraces(-0.75, 41, 80, pos=2, direction=1, col=Colors["Posterior"])

```


We originally introduced the prior into the scoring calculation in order to circumvent problems with extreme responses. However, in order to make sure that scores from all response options (extreme or not) are comparable, the prior is used in calculating all scores. This is also true for scores calculated from multiple items.  

To calculate a single score from an individualsâ responses to multiple items, we combine the probability curves through multiplication. This operation is analogous to calculating the joint probability of two independent events, e.g., the probability of obtaining two heads from two coin flips is calculated as 0.5 x 0.5 = 0.25. 

In calculating a score from multiple items, we multiply all response probabilities together, and then multiply by the prior to generate a set of single set of posterior probabilities, as in Figure \@ref(fig:MultiScoring) below. Figure \@ref(fig:MultiScoring) uses two response options probabilities from PROMIS Physical Function items PFA56 (*Are you able to get in and out of a car?*) and PFC46 (*Are you able to transfer from a bed to a chair and back?*). The probabilities in the graph of Figure \@ref(fig:MultiScoring) are scaled to make the posterior probability curve more visible. The dashed purple line represents the scaled response probabilities for extreme response option of PFC46, *Unable to do* and the dot-dashed brown line represents the scaled response probabilities of PFA56, *With some difficulty*. The solid green line represents the scaled prior probabilities and bold solid orange line represents the scaled probabilities of the posterior.  The process for calculating a single theta score from multiple items is the same as in the single item example in Figure \@ref(fig:ThetaCalcPosteriorProbMath).


```{r MultiScoring, dev="png", fig.path="Figures/", fig.cap="Expected A Posteriori scoring with multiple PROMIS Physical Function items", fig.width=8, fig.height=5, dpi=200}

  # This R Markdown chunk shows how multiple item responses are used to calculate a single theta score. 
    # The top half plots four probability curves,- two response option probability curves,   
    # the prior probability curve and the posterior probability curve- along with it's point of maximum likelihood.
    # Below the graphs there is a breakdown of how the theta quadrature allows us to perform simple multiplication
    # of the response probability curves with the prior probability curve across all levels of theta to calculate
    # the posterior probability curve. 

  # ni: Number of items = 2 (PFA51 & PFC46)
    ni=2

  # NCAT: Number of response categories in PFA51 & PFC46
    NCAT=c(Items$`Physical Function`$PFA56$NCAT, Items$`Physical Function`$PFC46$NCAT)
    
  # maxCat: Maximum number of response option categories in both PFA56 & PFC46
    maxCat=max(NCAT)
    
  # DISC: discrimination item calibration statistic, referred to as "a"
    DISC=rbind(Items$`Physical Function`$PFA56$Calibrations, Items$`Physical Function`$PFC46$Calibrations)[,"a"]
    
  # CB: threshold item calibration statistics, referred to as "cb"
    CB=rbind(Items$`Physical Function`$PFA56$Calibrations,
             Items$`Physical Function`$PFC46$Calibrations)[,paste0("cb",1:(maxCat-1))]

  # pp: 3d array of response probabilities for PFA56 & PFC46,
    # calculated with prep.prob() function and above variables
    pp<-prep.prob();

  # load the object 'pp' with dimension names: 
    # the first dimension is the theta quad. (-4 to 4 by 0.1 increments)
    # the second dimension is names of the items, PFA56 & PFC46
    # the third dimension is  names of the response options
    dimnames(pp)=list(
      c(round(theta,1)),
      c("PFA56", "PFC46"),
      names(sort(Items$`Physical Function`$PFA51$ResponseOptions)))
    
  # set the plotting margin parameters 
    par(mar=c(1,4,1,1))

  # Create an empty plotting space
    plot(NA, type="n", bty="n", xpd=TRUE, ann=FALSE, family="Times New Roman",
         xaxt="n", xlim=c(-1, dim(pp)[1]),
         yaxt="n", ylim=c(-3.5, 1))

  # Theta quadrature axis in the center of the graph space- position=0
    axis(1, pos=0, cex.axis=1, at=which(theta %in% seq(minTheta,maxTheta,1)), labels=Theta_axis_lab, family="Times New Roman") 

  # Probability axis tick marks every 50%
    axis(2, pos=which.min(as.numeric(dimnames(pp)[[1]])), cex.axis=1, family="Times New Roman", at=seq(0,1,0.5), cex=1, family="Times New Roman")

  # Plot response option probability curve for PFA56
    lines(pp[,"PFA56","With some difficulty"]/max(pp[,"PFA56","With some difficulty"]), col=Colors[3], lty=LineTypes[3])

  # Plot response option probability curve for PFC46
    lines(pp[,"PFC46","Unable to do"]/max(pp[,"PFC46","Unable to do"]), col=Colors[1], lty=LineTypes[1])

  # Plot prior probability curve
    lines(prior/max(prior),col=Colors["Prior"], lty=LineTypes["Prior"], lwd=LineWidth["Prior"])

  # Calculate posterior probability curve in two steps- multiply response probability curves together...
    posterior=pp[,"PFA56","With some difficulty"]*pp[,"PFC46","Unable to do"]

  # ...then multiply the product by the prior probability curve
    posterior=posterior*prior

  # Plot posterior probability curve
    lines(posterior/max(posterior), col=Colors["Posterior"], lty=LineTypes["Posterior"], lwd=LineWidth["Posterior"])

  # Calculate the theta weighted posterior by multiplying the posterior by theta
    thetaweightedposterior=posterior*theta

  # Calculate the final theta score by dividing the sum of theta-weighted posterior by sum of the posterior
    thetascore=sum(thetaweightedposterior)/sum(posterior)

  # Calculate the index of the thetascore along the length of the theta quadrature, 1:81
    thetascoreindex=which(round(theta,1)==round(as.numeric(thetascore),1))

  # Print the final theta score above the point of maximum likelihood of the posterior 
    text(x=thetascoreindex, y=0.25, pos=4, labels=round(thetascore,2), cex=1, family="Times New Roman")

  # Print vertical line on the final theta score (x axis) 
    segments(x0=thetascoreindex, x1=thetascoreindex, y0=0, y1=1)

  # Print "theta" centered under the graph area as the x axis
    text(length(dimnames(pp)[[1]])/2,-0.6, cex=1, "Theta", family="Times New Roman")

  # Print "Scaled Probability" centered to the left of the graph area as the y axis
    mtext("Scaled Probability", side=2, line=1.5, at=0.5, cex=1, family="Times New Roman")

  # Draw a horizontal line segment to represent the theta quadrature
    segments(y0=-1,y1=-1,x0=which.min(dimnames(pp)[[1]]),x1=which.max(dimnames(pp)[[1]]))

  # For each theta increment, "i", in the theta quadrature...
    for(i in as.numeric(dimnames(pp)[[1]])){
  
  # j: index of the theta increment, i,  in the length of the theta quadrature, 1:81 
    j=which(as.numeric(dimnames(pp)[[1]])==i)
  
  # Draw major tickmarks on 0.5 theta increments and minor tickmarks on all other increments
    if(!i%%0.5){segments(y0=-0.875,y1=-1.125,x0=j,x1=j)}
    else{segments(y0=-1.05,y1=-0.95,x0=j,x1=j)}
  
   # At all whole number increments of theta...
    if(!i%%1){
      
    # Print theta quadrature level
    text(j,-1.5,i, cex=1, family="Times New Roman")
      
    # Print response option probability 
    text(j,-2,format(round(pp[j,"PFA56","With some difficulty"],3),nsmall=3), cex=1, family="Times New Roman",
         col=Colors[3])
    
    # Print an "x" as a multiplication sign
    text(j,-2.25, "x", cex=1, family="Times New Roman")
    
    # Print response option probability
    text(j,-2.5,format(round(pp[j,"PFC46","Unable to do"],3),nsmall=3), cex=1, family="Times New Roman",
     col=Colors[1])
    
    # Print an "x" as a multiplication sign
    text(j,-2.75, "x", cex=1, family="Times New Roman")
    
    # Print prior probability
    text(j,-3,format(round(prior[j],3),nsmall=3), cex=1, col=Colors["Prior"], family="Times New Roman")
    
    # Print an equals sign 
    text(j,-3.25, "=", cex=1, family="Times New Roman")
    
    # Printer posterior probabilities
    text(j,-3.5,format(round(posterior[j],5),nsmall=3), cex=1, col=Colors["Posterior"], family="Times New Roman")}
  
    # At non-whole number 0.5 increments of theta print "..."
    if(!i%%0.5 & i%%1){
      text(j,-1.5,adj=c(0.5,0.6),"...", cex=1, family="Times New Roman")
      text(j,-2,adj=c(0.5,0.6),"...", cex=1, family="Times New Roman", col=Colors[3])
      text(j,-2.5,adj=c(0.5,0.6),"...", cex=1, family="Times New Roman", col=Colors[1])
      text(j,-3,adj=c(0.5,0.6),"...", cex=1, col=Colors["Prior"], family="Times New Roman")
      text(j,-3.5,adj=c(0.5,0.6),"...", cex=1, col=Colors["Posterior"], family="Times New Roman")}
    }

  # In the plot margin, print labels for the theta quadrature, response, prior and posterior probabilities
    mtext("Theta \n Quad. ", side=2, line=0.5, at=-1.5, cex=1, las=2, family="Times New Roman")
    mtext("Response \n Prob. ", side=2, line=0.5, at=-2, cex=1, las=2, family="Times New Roman", col=Colors[3])
    mtext("Response \n Prob. ", side=2, line=0.5, at=-2.5, cex=1, las=2, family="Times New Roman", col=Colors[1])
    mtext("Prior \n Prob.", side=2, line=0.5, at=-3, cex=1, las=2, col=Colors["Prior"], family="Times New Roman")
    mtext("Posterior \n Prob. ", side=2, line=0.5, at=-3.5, cex=1, las=2, col=Colors["Posterior"], family="Times New Roman")

```

## Practical Considerations of EAP Scoring {.unnumbered}

There are three practical considerations of EAP scoring: one consideration related to the ordering of items, one related to score resolution, and another related the bias of prior.

Figure \@ref(fig:MultiScoring) shows that EAP scoring uses simple multiplication to combine probabilities of multiple items.  A property of multiplication is that any order or arrangement of multiplications has the same result (e.g., 1x2x3 = 3x2x1).
Consequently, the order of items doesn't matter in EAP score calculation; a combination of item responses in any order will result in the same score.

The insensitivity to item order also means that the resolution of EAP scores increases exponentially with the number items answered. One item with five response options has 5 possible EAP scores (5^1^=5), two items have 25 possible EAP scores (5^2^=25) and three items have 125 possible EAP scores (5^3^=125). This is a large increase in score resolution over raw sum scoring methods, in which the same three items have only 13 possible sum scores, ranging from 3-15.

As shown in Figure \@ref(fig:RespCatProbThetaExtremePriorwMath), multiplication by the prior biases an EAP score inward.
However, since the prior is only multiplied once in calculation of the posterior, it's influence on the final EAP score will shrink as more items added into the calculation.

For these reasons, this tutorial doesnât recommend EAP scoring with fewer than 3 items. The shortest PROMIS short form has 4 items and PROMIS CAT will administer 4 items as the standard minimum.

# Raw Sum Score to IRT Look-up Table Scoring {.unnumbered}

The previous sections demonstrate that Expected A Posteriori scoring is flexible and can be efficiently calculated by computers, but requires both statistical coding and calibration statistics to generate scores from item responses. An alternative for PROMIS users who do not have access to calibration statistics and statistical code is a "look-up" table to convert a raw sum score to an EAP score. The scores in these look-up tables are calculated with EAP methods and represent the most probable theta level across all possible response pattern combinations for a single scale-level sum score. The maximum and minimum scale-level scores in the table relate to the floor and ceiling of the scale. Table \@ref(tab:LookUpTable) shows an example look-up table. 

Figure \@ref(fig:LookUpTableGraph) shows an example of how an EAP score for a raw sum score of 4 in Table \@ref(tab:LookUpTable) is calculated. In this example, three Physical Function items (PFA51, PFB25 and PFC46) make up a three-item scale. The minimum possible scale score on the three item scale is 3 (all three items have a raw score of 1) and maximum scale score of 15 (all three items have a raw score of 5), as shown in Table \@ref(tab:LookUpTable).

To calculate the EAP score for a scale-level raw sum score of 4, we first calculate the theta probabilities for each of the three possible combinations that sum to 4. Each response combination includes two 1's and one 2, i.e., 1,1,2; 1,2,1; 2,1,1. Each of the response probability curves are shown in the top three plots of Figure \@ref(fig:LookUpTableGraph). The total probability of multiple independent events (or in this case, three independent response patterns which each have a sum-score of 4) can be found by summation, shown in bottom of Figure \@ref(fig:LookUpTableGraph). The center plot in Figure \@ref(fig:LookUpTableGraph) shows each scaled probability curves, including the three dotted, dashed and dot-dashed response pattern probability curves, and their sum multiplied by the prior. The result is a posterior probability curve (bold solid orange line) with a theta maximum likelihood of -3.36 for all response combinations which sum to 4.

```{r LookUpTableCalc, include=FALSE}

# This R Markdown chunk shows how Expected A Posteriori scoring is done for a raw sum score to look-up table. The end result of this chunk is the creation of a 'scoring table' object, which includes the raw sum score to IRT look-up crosswalk table. 

# Create an 'ipar' data frame object (short for 'item parameter') which includes discrimination and threshold parameters
  ipar=data.frame(rbind(
    Items$`Physical Function`$PFA51$Calibrations,
    Items$`Physical Function`$PFB25$Calibrations,
    Items$`Physical Function`$PFC46$Calibrations))

# Add a NCAT column (number of categories) which is 5 for all items
  ipar$NCAT=5

# ni: number of items is three
  ni=3

# DISC: vector of discrimination statistics from the ipar object (item parameters)
	DISC<-ipar[,"a"]

# CB: data frame of discrimination statistics from the ipar object (item parameters)
	CB<-ipar[paste("cb",1:(maxCat-1),sep="")]

# pp: create an array object for the response probabilities of the three items 
  pp<-array(0,c(nq,ni,maxCat))
  		for (i in 1:ni) {
  			ps<-matrix(0,nq,NCAT+1)
  			ps[,1]<-1
  			ps[,NCAT]<-0
  			for (k in 1:(NCAT-1)) {ps[,k+1]<-1/(1+exp(-1*DISC[i]*(theta-CB[i,k])))}
  			pp[,i,1]<-1-ps[,1]
  			pp[,i,NCAT]<-ps[,NCAT]
  			for (k in 1:NCAT) {pp[,i,k]=ps[,k]-ps[,k+1]}
  		}

    dimnames(pp)=list(
        c(round(theta,1)),
        c("PFA51", "PFB25", "PFC46"),
        names(sort(Items$`Physical Function`$PFA51$ResponseOptions)))
    
  # Sets the minimum possible score to 0
    # This isn't a PROMIS Standard, but it is preserved incase a zero anchored scale is needed
  min.Raw.Score<-0 

  # Sets the max possible score to the number of response categories minus the number of items
   # This isn't a PROMIS Standard, but it is preserved in case a zero anchored scale is needed
	max.Raw.Score<-sum(ipar[,"NCAT"])-ni 

  # nScore: variable with the number of raw sum score points (+1 max-min)
	nScore<-max.Raw.Score-min.Raw.Score+1
	
	# TCCinv: Create TCC scoring table object
	TCCinv<-numeric(nScore) 
	
	# Raw.Score: vector of raw sum scores, ranging from the minimum to maximum
	Raw.Score<-min.Raw.Score:max.Raw.Score

	# LH: likelihood matrix, with theta quadrature across the rows and number of raw sum scores across the columns
	LH<-matrix(0,nq,nScore)

	ncat<-ipar[1,"NCAT"]
	
	# maxScore: variable that will store the maxScore for each item
	maxScore<-0
	
	# Initialize the Likelihood matrix with the probabilities from the response probabilities of the first item, for all response probabilities (1:ncat)
	LH[,1:ncat]<-pp[,1,1:ncat]
	
	# idx: index variable that starts with NCAT
	idx<-ncat

	# from the second item to the last item (represented by, ni - number of items) cycle through items included in the scoring table, "i" ...
	for (i in 2:ni) {
	  
	  # reload the 'ncat' variable with the number 
		ncat<-ipar[i,"NCAT"]
		
		# reload 'maxScore' with number of item response categories
		maxScore<-ncat-1
		
		# reload the score vector with raw sum scores from 0 (minimum) to maxScore
		score<-0:maxScore 
		
		# prob: matrix with response probabilities for response options (1:ncat) for item 'i'
		prob<-pp[,i,1:ncat]

		# pLH: empty (all zero's) matrix with rows equal to number of quadrature points and columns equal to the number of scale-level raw sum scores
		pLH<-matrix(0,nq,nScore)
		
	  # for each response option, "k", in item "i" (1:ncat)...
		for (k in 1:ncat) {
		  
		  # for each level "h" in 1:idx
			for (h in 1:idx) {
			  
			  # sco is score placeholder for the raw sum score of the item (h) existing scale-level score[k]
				sco<-Raw.Score[h]+score[k]
				
				# position: holder for the which Raw.Score equals sco
				position<-which(Raw.Score==sco)
				
				# pLH: add in LH and prob[,k]*LH[,h]
				pLH[,position]<-pLH[,position]+LH[,h]*prob[,k]
			}
		}
		
		# increase the idx variable by the max score for the items
		idx<-idx+maxScore
		
		# recreate the likelihood with the placeholder likelihood
		LH<-pLH
	}

	# Initialize Raw Sum Scoring vector 
	Scale.Score<-numeric(nScore) 
	
	# Initialize Standard Error vector 
	SE<-numeric(nScore)

	# Posterior Distribution, multiply the likelihood by the prior
	posterior<-LH*prior
	
	# create a denominator with column sums of the posterior
	den<-colSums(posterior)
	
	# create denominator matrix of denominator 
	den<-matrix(rep(den,rep(nq,nScore)),nq,nScore)
	
	# create a posterior score by denominator
	posterior<-posterior/den

	
	# from the each score, "j" in 1:nScore ...
	for (j in 1:nScore) {
	  
	  # load the Scale IRT EAP Score for with sum(posterior * theta)/ sum(posterior) 
		Scale.Score[j]<-sum(posterior[,j]*theta)/sum(posterior[,j]) #EAP
		
		# load the SE for EAP IRT  
		SE[j]<-sqrt(sum(posterior[,j]*(theta-Scale.Score[j])^2)/sum(posterior[,j])) #EAP
	}

	# Raw score = raw score + ni
	  # This makes the sum scores anchored at 1 instead of 0
	Raw.Score<-Raw.Score+ni #can cut this after removal for the -ni up top

# Scoring table data frame with both Raw Scores and IRT Scale Scores
Scoring.Table=data.frame("Raw"=Raw.Score,"IRT"=round(Scale.Score,2))

```

```{r LookUpTable, results='asis'}
# This chunk creates the Scoring Table from the knitr kable
knitr::kable(Scoring.Table, align="c", caption = "IRT to Raw Sum Score Look-up Table")

```

```{r LookUpTableGraph, dev="png", fig.path="Figures/", fig.cap="Calculation of most likely IRT score for raw sum score of 4", fig.width=8, fig.height=7, dpi=200}

# Set the plotting margins
  par(family="Times New Roman", mar=c(4,6,3,1))

# Set the figure layout to three images up top and one big one below
  layout(matrix(c(1:3,rep(4,9)), nrow=4, ncol=3, byrow = TRUE))

# Set the three response patterns for a raw sum score
  ResponsePatterns=c("1,1,2", "1,2,1", "2,1,1")

# Calculate the response probabilities of three response probailities
  ResponseCombinations=data.frame(
    "pattern_1.1.2"=pp[,1,1]*pp[,2,1]*pp[,3,2],
    "pattern_1.2.1"=pp[,1,1]*pp[,2,2]*pp[,3,1],
    "pattern_2.1.1"=pp[,1,2]*pp[,2,1]*pp[,3,1])

# Calculate the posterior by multiplying by the prior
  posterior=rowSums(ResponseCombinations)*prior

# Calculate the IRT EAP score for a raw sum score of 4
  RSS4EAPScore=sum(posterior*theta)/sum(posterior)

# Plot all the response option probability curves
  for(i in 1:3){
      plot(ResponseCombinations[,i], 
      main=paste("Probabilities across Theta \n for Response Combination:", ResponsePatterns[i]),
      ylab="Probability", ylim=c(0,0.2),
      type="l", col=Colors[i], lty=LineTypes[i],
      xaxt="n", xlab="Theta", cex.main=1.125)
      axis(1, at=which(theta %in% seq(minTheta,maxTheta,1)), cex=1.25, labels=seq(minTheta,maxTheta,1), family="Times New Roman")}

  # Set the margins
  par(family="Times New Roman", mar=c(1,6,3,1))
  
# Plot the posterior 
  plot(posterior/max(posterior),
        main="Probability Densities for All Response Combinations, Prior and EAP Score ", cex.main=1.25, bty="n",
        yaxt="n", ylim=c(-4, 1), ylab="",
        xaxt="n", xlim=c(-1, dim(pp)[1]), xlab="", 
        type="l", col=Colors["Posterior"], lty=LineTypes["Posterior"], lwd=LineWidth["Posterior"])

# Theta quadrature axis in the center of the graph space- position=0
  axis(1, pos=0, cex.axis=1.25, at=which(theta %in% seq(minTheta,maxTheta,1)), labels=Theta_axis_lab, family="Times New Roman") 

# Probability axis tick marks every 25%
  axis(2, pos=which.min(as.numeric(dimnames(pp)[[1]])), cex.axis=1.25, family="Times New Roman", at=seq(0,1,0.25), cex=1, family="Times New Roman")

# Plot probability lines
  for(i in 1:3){lines(ResponseCombinations[,i]/max(ResponseCombinations[,i]),col=Colors[i], lty=LineTypes[i])}
  lines(prior/max(prior), col=Colors["Prior"], lty=LineTypes["Prior"], lwd=LineWidth["Prior"])
  segments(x0=which(theta==round(RSS4EAPScore,1)), x1=which(theta==round(RSS4EAPScore,1)), y0=0,y1=1)
  text(x=which(theta==round(RSS4EAPScore,1)),y=1,labels=round(RSS4EAPScore,2), cex=1.25, pos=4, family="Times New Roman")

# Calculate the theta weighted posterior by multiplying the posterior by theta
  thetaweightedposterior=posterior*theta

# Calculate the final theta score by dividing the sum of theta-weighted posterior by sum of the posterior
  thetascore=sum(thetaweightedposterior)/sum(posterior)

# Calculate the index of the thetascore along the length of the theta quadrature, 1:81
  thetascoreindex=which(round(theta,1)==round(as.numeric(thetascore),1))

# Print "theta" centered under the graph area as the x axis
  text(length(dimnames(pp)[[1]])/2,-0.6, cex=1.25, "Theta", family="Times New Roman")

# Print "Scaled Probability" centered to the left of the graph area as the y axis
  mtext("Scaled Probability", side=2, line=1.5, at=0.5, cex=1, family="Times New Roman")

# Draw a horizontal line segment to represent the theta quadrature
  segments(y0=-1,y1=-1, x0=1, x1=81)

# For each theta increment, "i", in the theta quadrature...
  for(i in as.numeric(dimnames(pp)[[1]])){
  
  # j: index of the theta increment, i,  in the length of the theta quadrature, 1:81 
    j=which(as.numeric(dimnames(pp)[[1]])==i)
    
  # Draw major tickmarks on 0.5 theta increments and minor tickmarks on all other increments
    if(!i%%0.5){segments(y0=-0.875,y1=-1.125,x0=j,x1=j)}
    else{segments(y0=-1.05,y1=-0.95,x0=j,x1=j)}
  
  # At all whole number increments of theta...
    if(!i%%1){
    
    # Print theta quadrature level
      text(j,-1.5,i, cex=1.25, family="Times New Roman")
      CurlyBraces(-1.9, j, 5, pos = 2, direction = 1, size = 0.125)
    
    # Print response option probability 
      text(j,-2,format(round(ResponseCombinations[j,1],4),nsmall=3), cex=1.25, family="Times New Roman", col=Colors[1])
      
    # Print an "+" as a multiplication sign
      text(j,-2.25, "+", cex=1.25, family="Times New Roman")
      
    # Print response option probability
      text(j,-2.5,format(round(ResponseCombinations[j,2],4),nsmall=3), cex=1.25, family="Times New Roman", col=Colors[2])
      
    # Print an "+" as a multiplication sign
      text(j,-2.75, "+", cex=1.25, family="Times New Roman")
    
    # Print response option probability
      text(j,-3,format(round(ResponseCombinations[j,3],4),nsmall=3), cex=1.25, family="Times New Roman", col=Colors[3])
      CurlyBraces(-3.1, j, 5, pos = 2, direction = 2, size = 0.125)

    # Print an "x" as a multiplication sign
      text(j,-3.25, "x", cex=1.25, family="Times New Roman")    
        
    # Print prior probability
      text(j,-3.5,format(round(prior[j],4),nsmall=3, scientific = FALSE), cex=1.25, col=Colors["Prior"], family="Times New Roman")
      
    # Print an equals sign 
      text(j,-3.75, "=", cex=1.25, family="Times New Roman")
      
    # Print posterior probabilities
      text(j,-4,format(round(posterior[j],5),nsmall=3, scientific=FALSE), cex=1.25, col=Colors["Posterior"], family="Times New Roman")}
  
    # At non-whole number 0.5 increments of theta print "..."
      if(!i%%0.5 & i%%1){
        text(j,-1.5,adj=c(0.5,0.6),"...", cex=1.25, family="Times New Roman")
        text(j,-2,adj=c(0.5,0.6),"...", cex=1.25, family="Times New Roman", col=Colors[1])
        text(j,-2.5,adj=c(0.5,0.6),"...", cex=1.25, family="Times New Roman", col=Colors[2])
        text(j,-3,adj=c(0.5,0.6),"...", cex=1.25, family="Times New Roman", col=Colors[3])
        text(j,-3.5,adj=c(0.5,0.6),"...", cex=1.25, col=Colors["Prior"], family="Times New Roman")
        text(j,-4, adj=c(0.5,0.6),"...", cex=1.25, col=Colors["Posterior"], family="Times New Roman")}
      }

# In the plot margin, print labels for the theta quadrature, response, prior and posterior probabilities
  mtext("Theta \n Quad. ", side=2, line=0.5, at=-1.5, cex=1, las=2, family="Times New Roman")
  mtext("Response \n Prob. ", side=2, line=0.5, at=-2, cex=1, las=2, family="Times New Roman", col=Colors[1])
  mtext("Response \n Prob. ", side=2, line=0.5, at=-2.5, cex=1, las=2, family="Times New Roman", col=Colors[2])
  mtext("Response \n Prob. ", side=2, line=0.5, at=-3, cex=1, las=2, family="Times New Roman", col=Colors[3])
  mtext("Prior \n Prob.", side=2, line=0.5, at=-3.5, cex=1, las=2, col=Colors["Prior"], family="Times New Roman")
  mtext("Posterior \n Prob. ", side=2, line=0.5, at=-4, cex=1, las=2, col=Colors["Posterior"], family="Times New Roman")

```


In order to differentiate between the two forms of scoring, one is referred to as "response pattern scoring" or "pattern response scoring" because it uses an individual's pattern of responses and the other is referred to as "look-up table scoring". Scores calculated for a look-up table are typically very highly correlated (e.g., \>0.9) with response pattern scoring. Figure \@ref(fig:LookUpPatternResponseScoreCorrelation) shows a plot of look-up and pattern response scoring methods for all response option combinations of the three physical function items used in Table \@ref(tab:LookUpTable) and Figure \@ref(fig:LookUpTableGraph). The two scoring methods have a pearson correlation coefficient of 0.96. For this reason, the scores from these two scoring methods are considered to be interchangeable, as mentioned in @Hanmer2020Checklist. Pattern response scoring methods are more sensitive to an individual's pattern of responses and are recommended whenever possible, but look-up table scoring is a good alternative. Foundational citations and additional examples of look-up table scoring methods are published in @Cai2015RSSS and  @Lord1984RSSS.


```{r LookUpPatternResponseScoreCorrelation, dev="png", fig.path="Figures/", fig.cap="Comparison of look-up and pattern response Expected A Posteriori scoring methods", fig.width=3.5, fig.height=3.5, dpi=200}


# This R Markdown chunk calculates and plots the relationship between 
  # Expected A Posteriori 'Pattern Response' versus 'Look-up table' scoring

source("ThetaSEeap.R")
source("RSSS.R")

# Create the Raw Sum Score table with the rsss function and ipar
  RSSS_table=rsss(ipar)

# LUPR: create a response option grid for calculating LookUp Pattern vs Pattern Response scoring
  # the base R expand grid function creates all possible response patterns
  LUPR_data=expand.grid("PFA51"=1:5,"PFB25"=1:5, "PFC46"=1:5)

# Create pattern response scoring for all response option
  PR_theta=thetaSE.eap(ipar, LUPR_data)$theta

# Create look up table scoring based on all response options
  LU_theta=(RSSS_table$Scale[match(apply(LUPR_data, 1, sum), RSSS_table$Raw)]-50)/10

# Set the plotting margins
  par(mar=c(4,4,1,1))

  
# Create the plot for pattern response and lookup table scoring
  plot(PR_theta, LU_theta, family="Times New Roman",
       xlim=c(-4, 4), xlab="Response Pattern Scores",
       ylim=c(-4, 4), ylab="Look Up Table Scores")

# Plot the pearson correlation coefficient between pattern response and lookup table scoring
  text(2,2, paste("r =", round(cor(PR_theta, LU_theta),2)), family="Times New Roman")


```


# Posterior Standard Deviation and Standard Error {.unnumbered}

Because of the inclusion of the prior in estimating the theta score, EAP scores don't have a traditional standard error. Instead, we can calculate the standard deviation of the posterior distribution. The method for calculating the posterior standard deviation is the same for both pattern-response and look-up table scoring methods. Formula \@ref(eq:PosteriorSD) details the calculation of the posterior standard deviation.  

There are parallels between the posterior standard deviation and the common standard deviation formula \@ref(eq:SD), notably, the size of the numerator of both formulas is driven by the sum of squared deviations from a single point, either the EAP score in Formula \@ref(eq:PosteriorSD) or the mean in Formula \@ref(eq:SD) and both Formulas use a square root. They differ in that the squared deviation at each level of the theta quadrature is multiplied by the posterior probability before summation in Formula \@ref(eq:PosteriorSD), and that the sum of the posterior distribution is the denominator in Formula \@ref(eq:PosteriorSD) and the sample size is in the denominator of Formula \@ref(eq:SD).


\begin{equation}
Posterior\:SD ={\sqrt{ \frac{\sum(Posterior*(Theta\:Quadrature-EAP\:Score)^2)} {\sum(Posterior)} }}
(\#eq:PosteriorSD)
\end{equation}

\begin{equation}
SD= {\sqrt{\frac{\sum(X-\bar{X})^2}{N}}}
(\#eq:SD)
\end{equation}

While the posterior standard deviation is not a standard error, it is related in a number of ways. The posterior standard deviation is a function of the shape of the posterior probability curve, which is informed by the consistency of response probabilities and the number of items scored.  

Figure \@ref(fig:PosteriorStandardDeviationPlot) shows an example of the relationship between number of items, consistency of responses and the posterior standard deviation. The gray shaded area under the bold solid orange posterior probability curve in Figure \@ref(fig:PosteriorStandardDeviationPlot) indicates a bandwidth of one standard deviation from the EAP score. Generally, a smaller posterior standard deviation occurs with a larger number of items with consistent responses, which maps onto a smaller standard error. Conversely, a smaller number of inconsistent item responses leads to a larger posterior standard deviation and larger standard error. @Bock1982EAP draw a direct and "near identity" relationship between the posterior standard deviation and standard error as the number of items increases (p. 437).

Similar to how T-scores are a linear transformation of theta (Formula \@ref(eq:Tscore)), posterior standard deviations can be put on the T-score metric by multiplication by 10, e.g., a posterior standard deviation of 0.21 on the theta metric is a posterior standard deviation of 2.1 on the T-score metric. 

```{r PosteriorStandardDeviationPlot, dev="png", fig.path="Figures/", fig.cap="Posterior standard deviation, number of items and response consistency" , fig.width=8, fig.height=6, dpi=200}

# ni: Number of items = 6 
  ni=6

# NCAT= Number of response categories in the six items
  NCAT=c(Items$`Physical Function`$PFA56$NCAT,
         Items$`Physical Function`$PFC46$NCAT,
         Items$`Physical Function`$PFA51$NCAT,
         Items$`Physical Function`$PFB25$NCAT,
         Items$`Physical Function`$PFA16$NCAT,
         Items$`Physical Function`$PFA11$NCAT)

# maxCat: Maximum number of response option categories in both PFA56 & PFC46
  maxCat=max(NCAT)

# DISC: discrimination item calibration statistic, referred to as "a"
  DISC=rbind(Items$`Physical Function`$PFA56$Calibrations,
             Items$`Physical Function`$PFC46$Calibrations,
             Items$`Physical Function`$PFA51$Calibrations,
             Items$`Physical Function`$PFB25$Calibrations,
             Items$`Physical Function`$PFA16$Calibrations,
             Items$`Physical Function`$PFA11$Calibrations)[,"a"]

# CB: threshold item calibration statistics, referred to as "cb"
  CB=rbind(Items$`Physical Function`$PFA56$Calibrations,
           Items$`Physical Function`$PFC46$Calibrations,
           Items$`Physical Function`$PFA51$Calibrations,
           Items$`Physical Function`$PFB25$Calibrations,
           Items$`Physical Function`$PFA16$Calibrations,
           Items$`Physical Function`$PFA11$Calibrations)[,paste0("cb",1:(maxCat-1))]


# pp: 3d array of response probabilities for PFA56 & PFC46,
  # calculated with prep.prob() function and above variables
  pp<-prep.prob();

  dimnames(pp)=list(
    c(round(theta,1)),
    c("PFA56", "PFC46", "PFA51", "PFB25", "PFA16", "PFA11"),
    names(sort(Items$`Physical Function`$PFA51$ResponseOptions)))

# Set the two by two plotting space, outer margins, font and main font
  par(mfrow=c(2,2), oma=c(2, 3.5, 2, 3.5), family="Times New Roman", cex.main=0.875)

# 3 items w/inconsistent responses
  posterior=pp[,1,1]*pp[,2,3]*pp[,3,5]*prior
  EAPScore=sum(posterior*theta)/sum(posterior)
  PSD=sqrt(sum(posterior*(theta-EAPScore)^2)/sum(posterior))

# bounds: list of lower and upper bounds of bandwidth of 1 SD
  bounds=list("lower"=EAPScore-PSD, "upper"=EAPScore+PSD)

# boundsindex: list of location on theta quadrature (1:81) of lower and upper bounds of bandwidth of 1 SD
  boundsindex=list("lower"=which(theta==round(bounds$lower,1)), "upper"=which(theta==round(bounds$upper,1)))

# Create the plotting space
  plot(NA, type="n", family="Times New Roman",
    main=paste0("Posterior Standard Deviation = ", round(PSD,2)),
    xaxt="n", xlab="Theta", xlim=c(0, dim(pp)[1]),
    yaxt="n", ylab="Scaled Probability", ylim=c(0, 1))

# draw the 1 SD space under the posterior probability curve
  polygon(c(boundsindex$lower:boundsindex$upper, boundsindex$upper, boundsindex$lower), 
    c(posterior[boundsindex$lower:boundsindex$upper]/max(posterior), 0, 0), 
    col="gray", round(bounds$lower,2), density = 75)

# draw the vertical line where the EAP score is
  segments(x0=which(theta==round(EAPScore,1)), x1=which(theta==round(EAPScore,1)),
    y0=0, y1=posterior[which(theta==round(EAPScore,1))]/max(posterior), col="white")

# Plot the posterior probability curve
  lines(posterior/max(posterior), col=Colors["Posterior"], lty=LineTypes["Posterior"], lwd=LineWidth["Posterior"])

# Draw the X axis with the theta quadrature 
  axis(1, at=which(theta %in% seq(minTheta,maxTheta,1)), labels=seq(minTheta,maxTheta,1), family="Times New Roman")

# Probability axis tickmarks every 50%
  axis(2, line=0, cex.axis=0.75, at=seq(0,1,0.5), cex=0.75, family="Times New Roman")


# 3 items w/consistent responses
  posterior=pp[,1,3]*pp[,2,3]*pp[,3,3]*prior
  EAPScore=sum(posterior*theta)/sum(posterior)
  PSD=sqrt(sum(posterior*(theta-EAPScore)^2)/sum(posterior))

# bounds: list of lower and upper bounds of bandwidth of 1 SD
  bounds=list("lower"=EAPScore-PSD, "upper"=EAPScore+PSD)

# bounds: list of location on theta quadrature (1:81) of lower and upper bounds of bandwidth of 1 SD  
  boundsindex=list("lower"=which(theta==round(bounds$lower,1)), "upper"=which(theta==round(bounds$upper,1)))

# draw the plotting space
  plot(NA, type="n", family="Times New Roman",
   main=paste0("Posterior Standard Deviation = ", round(PSD,2)),
   xaxt="n", xlab="Theta", xlim=c(0, dim(pp)[1]),
   yaxt="n", ylab="Scaled Probability", ylim=c(0, 1))

# draw the 1 SD space under the posterior probability curve
  polygon(c(boundsindex$lower:boundsindex$upper, boundsindex$upper, boundsindex$lower), 
    c(posterior[boundsindex$lower:boundsindex$upper]/max(posterior), 0, 0), 
    col="gray", round(bounds$lower,2), density = 75)

# draw the vertical line where the EAP score is
  segments(x0=which(theta==round(EAPScore,1)), x1=which(theta==round(EAPScore,1)),
     y0=0, y1=posterior[which(theta==round(EAPScore,1))]/max(posterior),
     col="white")

# Plot the posterior probability curve
  lines(posterior/max(posterior), col=Colors["Posterior"], lty=LineTypes["Posterior"], lwd=LineWidth["Posterior"])

# Draw the X axis with the theta quadrature
  axis(1, at=which(theta %in% seq(minTheta,maxTheta,1)), labels=seq(minTheta,maxTheta,1), family="Times New Roman")

# Probability axis tickmarks every 50%
  axis(2, line=0, cex.axis=0.75, at=seq(0,1,0.5), cex=0.75, family="Times New Roman")

# 6 items w/inconsistent responses
  posterior=pp[,1,1]*pp[,2,4]*pp[,3,1]*pp[,4,4]*pp[,5,1]*pp[,6,5]*prior
  EAPScore=sum(posterior*theta)/sum(posterior)
  PSD=sqrt(sum(posterior*(theta-EAPScore)^2)/sum(posterior))

# bounds: list of lower and upper bounds of bandwidth of 1 SD
  bounds=list("lower"=EAPScore-PSD, "upper"=EAPScore+PSD)

# bounds: list of location on theta quadrature (1:81) of lower and upper bounds of bandwidth of 1 SD
  boundsindex=list("lower"=which(theta==round(bounds$lower,1)), "upper"=which(theta==round(bounds$upper,1)))

# draw the plotting space
  plot(NA, type="n", family="Times New Roman",
       main=paste0("Posterior Standard Deviation = ", round(PSD,2)),
       xaxt="n", xlab="Theta", xlim=c(0, dim(pp)[1]),
       yaxt="n", ylab="Scaled Probability", ylim=c(0, 1))

# draw the 1 SD space under the posterior probability curve
  polygon(c(boundsindex$lower:boundsindex$upper, boundsindex$upper, boundsindex$lower), 
          c(posterior[boundsindex$lower:boundsindex$upper]/max(posterior), 0, 0), 
          col="gray", round(bounds$lower,2), density = 75)

# draw the vertical line where the EAP score is
  segments(x0=which(theta==round(EAPScore,1)), x1=which(theta==round(EAPScore,1)),
           y0=0, y1=posterior[which(theta==round(EAPScore,1))]/max(posterior),
           col="white")

# Plot the posterior probability curve
  lines(posterior/max(posterior), col=Colors["Posterior"], lty=LineTypes["Posterior"], lwd=LineWidth["Posterior"])

# Draw the X axis with the theta quadrature
  axis(1, at=which(theta %in% seq(minTheta,maxTheta,1)), labels=seq(minTheta,maxTheta,1), family="Times New Roman")

# Probability axis tickmarks every 50%
  axis(2, line=0, cex.axis=0.75, at=seq(0,1,0.5), cex=0.75, family="Times New Roman")

# 6 items w/consistent responses
  posterior=pp[,1,3]*pp[,2,3]*pp[,3,3]*pp[,4,3]*pp[,5,3]*pp[,6,1]*prior
  EAPScore=sum(posterior*theta)/sum(posterior)
  PSD=sqrt(sum(posterior*(theta-EAPScore)^2)/sum(posterior))

# bounds: list of lower and upper bounds of bandwidth of 1 SD
  bounds=list("lower"=EAPScore-PSD, "upper"=EAPScore+PSD)

# bounds: list of location on theta quadrature (1:81) of lower and upper bounds of bandwidth of 1 SD  
  boundsindex=list("lower"=which(theta==round(bounds$lower,1)), "upper"=which(theta==round(bounds$upper,1)))

# draw the plotting space
  plot(NA, type="n", family="Times New Roman",
   main=paste0("Posterior Standard Deviation = ", round(PSD,2)),
   xaxt="n", xlab="Theta", xlim=c(0, dim(pp)[1]),
   yaxt="n", ylab="Scaled Probability", ylim=c(0, 1))

# draw the 1 SD space under the posterior probability curve
  polygon(c(boundsindex$lower:boundsindex$upper, boundsindex$upper, boundsindex$lower), 
    c(posterior[boundsindex$lower:boundsindex$upper]/max(posterior), 0, 0), 
    col="gray", round(bounds$lower,2), density = 75)

# draw the vertical line where the EAP score is
  segments(x0=which(theta==round(EAPScore,1)), x1=which(theta==round(EAPScore,1)),
     y0=0, y1=posterior[which(theta==round(EAPScore,1))]/max(posterior),
     col="white")
  
# Plot the posterior probability curve
  lines(posterior/max(posterior), col=Colors["Posterior"], lty=LineTypes["Posterior"], lwd=LineWidth["Posterior"])

# Draw the X axis with the theta quadrature
  axis(1, at=which(theta %in% seq(minTheta,maxTheta,1)), labels=seq(minTheta,maxTheta,1), family="Times New Roman")

# Probability axis tickmarks every 50%
  axis(2, line=0, cex.axis=0.75, at=seq(0,1,0.5), cex=0.75, family="Times New Roman")
  
# Create margin text for the graph
  mtext(bquote(underline("Consistent Responses")), side=3, line=0, at=0.75, outer=TRUE)
  mtext(bquote(underline("Inconsistent Responses")), side=3, line=0, at=0.25, outer=TRUE)
  mtext(bquote(underline("Three Items")), side=2, line=0.75, at=0.75, font=2, outer=TRUE)
  mtext(bquote(underline("Six Items")), side=2, line=0.75, at=0.25, font=2, outer=TRUE)
  mtext("Gray area indicates EAP score Â± posterior standard deviation", side=1, font=3, cex=0.75, outer=TRUE)


```

# Conclusion {.unnumbered}

Expected A Posteriori (EAP) scoring is a flexible and efficient scoring method that can be performed without complex calculations and can be visualized and logically explained. Item response option probabilities distributed across a latent trait spectrum, theta, are the building blocks of EAP scoring and the maximum likelihood of these probabilities can provide a score estimate. Introduction of a theta quadrature and a Bayesian "prior" simplifies complex mathematical operations and alleviates measurement problems. For users who don't have access to the statistical code and item calibration statistics, a scale-level raw sum score to EAP score look-up table can be calculated. A posterior standard deviation can be calculated for all EAP scoring methods, which reflects the score standard error. A more complete understanding of the operation and options in PROMIS EAP scoring will help ground PROMIS IRT methods with existing users and will support the further adoption and implementation of PROMIS among researchers, clinicians and regulators.  


# List of Appendices and Attachments {.unnumbered}

### ThetaSEeap.R  {.unnumbered}
The "ThetaSEeap.R" script is an R script for calculating "pattern response" EAP scores, and was originally written by @ThetaSEeap.  

### RSSS.R  {.unnumbered}
The "RSSS.R" script is an R script for calculating EAP to raw sum score "Look Up" tables, and was originally written by @RSSS.   


\newpage

# References {.unnumbered}

<div id="refs"></div>


\newpage

# Appendices {.unnumbered}

## ThetaSEeap.R {.unnumbered}

```{r ThetaSEeap, code = readLines("ThetaSEeap.R"), echo=TRUE}

```

\newpage

## RSSS.R {.unnumbered}

```{r RSSS, code = readLines("RSSS.R"), echo=TRUE}

```

